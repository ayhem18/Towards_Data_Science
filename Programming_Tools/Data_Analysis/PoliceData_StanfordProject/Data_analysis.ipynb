{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysing Police Data\n",
    "This notebook is my attempt to analyze the police data provided by the Stanford Open Police Project. The intercation between police and civilians is documented for a number of states. Yet, only the data from Rhode Island state is considered in this analysis. The data can be found via this [link](https://openpolicing.stanford.edu/data/)  \n",
    "More Information about the dataset can be found on this [README](https://github.com/stanford-policylab/opp/blob/master/data_readme.md) file. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loc = os.path.join(\"data.csv\") # change depending on the data's location in the local machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_org = pd.read_csv(data_loc)\n",
    "df = df_org.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.head())\n",
    "print(df.shape) # we have such a large dataset with 500k rows and 31 columns\n",
    "df.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "Data is inherently dirty. Clearning the data is a fundamental and crucial step in the data analysis process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nan values\n",
    "Nan values are the convention to represent unavailable data whether it is missing, corrupted or simply data that does not fit in the specific column. Such values should be either dropped, or imputed for further data manipulation and drawing meaningfull conclusions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.info()\n",
    "# we can see that certain rows have a large number of Nan values\n",
    "nan_ratios = df.isna().sum() / len(df)\n",
    "# good cols are assumed to have at most 10% Nan values\n",
    "high_nan_cols = nan_ratios[nan_ratios > 0.9].index\n",
    "\n",
    "df.drop(high_nan_cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape) # dropping 10 columns\n",
    "# let's consider now the nan values\n",
    "print(df.isna().sum()) \n",
    "# the vehicle make or model does not seem of much importance\n",
    "# let's drop both such model\n",
    "df.drop(['raw_row_number', 'vehicle_make', 'vehicle_model'], axis=1, inplace=True)\n",
    "\n",
    "# among the interesting points in that dataset is to understand the relation between sex, race, so all row with nan values in this columns \n",
    "# are to be dropped\n",
    "df.dropna(subset=['subject_race', 'subject_sex'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.isna().sum()) # only one column is left with Nan values. We are ready to proceed with the data analysis.\n",
    "print(df.shape) # "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixing DataTypes \n",
    "Types are of importance as they define the operations that can be performed on the values as well as the efiiciency of working with them. Leaving as few object columns as possible is a good start.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.dtypes) # assigning the right data types to columns could optimize the entire process.\n",
    "# let's check columns 5 by 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2006-05-21    294\n",
      "2015-09-05    292\n",
      "2005-11-05    283\n",
      "2012-01-08    278\n",
      "2012-01-07    275\n",
      "             ... \n",
      "2005-01-12      1\n",
      "2005-05-11      1\n",
      "2005-06-06      1\n",
      "2005-08-08      1\n",
      "2005-06-18      1\n",
      "Name: date, Length: 3803, dtype: int64\n",
      "date's type: object\n",
      "None\n",
      "10:00:00    1677\n",
      "11:00:00    1660\n",
      "10:30:00    1552\n",
      "09:00:00    1548\n",
      "09:30:00    1400\n",
      "            ... \n",
      "05:09:00       7\n",
      "05:19:00       7\n",
      "04:52:00       7\n",
      "05:27:00       7\n",
      "05:22:00       5\n",
      "Name: time, Length: 1440, dtype: int64\n",
      "time's type: object\n",
      "None\n",
      "X4    125670\n",
      "K3    108868\n",
      "K2     97281\n",
      "X3     89431\n",
      "K1     46110\n",
      "X1     13224\n",
      "Name: zone, dtype: int64\n",
      "zone's type: object\n",
      "None\n",
      "white                     344716\n",
      "black                      68577\n",
      "hispanic                   53123\n",
      "asian/pacific islander     12824\n",
      "other                       1344\n",
      "Name: race, dtype: int64\n",
      "race's type: object\n",
      "None\n",
      "male      349446\n",
      "female    131138\n",
      "Name: sex, dtype: int64\n",
      "sex's type: object\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 5):\n",
    "    new_series = pd.Series(df.iloc[:, i])\n",
    "    print(new_series.value_counts()) # we can see that zone, race, gender can be converted to category datatype. \n",
    "    print(print(new_series.name + \"'s type: \" + str(new_series.dtype)))\n",
    "# first let's set rename some columns\n",
    "df.rename(columns={\"subject_race\": \"race\", \"subject_sex\":\"sex\"}, inplace=True)\n",
    "\n",
    "# convert type to category\n",
    "df['zone'] = df['zone'].astype('category')\n",
    "df['race'] = df['race'].astype('category')\n",
    "df['sex'] = df['sex'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500    114274\n",
      "300     87077\n",
      "900     71600\n",
      "200     70925\n",
      "600     28568\n",
      "        ...  \n",
      "20          1\n",
      "MA          1\n",
      "501         1\n",
      "1.0         1\n",
      "006         1\n",
      "Name: department_id, Length: 75, dtype: int64\n",
      "department_id's type: object\n",
      "None\n",
      "\n",
      "vehicular    480584\n",
      "Name: type, dtype: int64\n",
      "type's type: object\n",
      "None\n",
      "\n",
      "False    463981\n",
      "True      16603\n",
      "Name: arrest, dtype: int64\n",
      "arrest's type: bool\n",
      "None\n",
      "\n",
      "True     428378\n",
      "False     52206\n",
      "Name: citation, dtype: int64\n",
      "citation's type: bool\n",
      "None\n",
      "\n",
      "False    451744\n",
      "True      28840\n",
      "Name: warning, dtype: int64\n",
      "warning's type: bool\n",
      "None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5, 10):    \n",
    "    new_series = pd.Series(df.iloc[:, i])\n",
    "    print(new_series.value_counts())  \n",
    "    print(print(new_series.name + \"'s type: \" + str(new_series.dtype)))  \n",
    "    print()\n",
    "# arrest_made, citation_made and warning_issued should be converted to boolean\n",
    "df.rename(columns={\"arrest_made\": \"arrest\", \"citation_issued\": \"citation\", \"warning_issued\":\"warning\"}, inplace=True)\n",
    "df['arrest'] = df['arrest'].astype(bool)\n",
    "df['warning'] = df['warning'].astype(bool)\n",
    "df['citation'] = df['citation'].astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vehicular    480584\n",
      "Name: type, dtype: int64\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# what is even more interesting here is the type column \n",
    "print(df['type'].value_counts())\n",
    "print(df['type'].isna().sum())\n",
    "# the type is the same across the dataset which eliminates the need for that column\n",
    "df.drop('type',axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10, 15):\n",
    "    new_series = pd.Series(df.iloc[:, i])\n",
    "    print(new_series.value_counts())  \n",
    "    print(print(new_series.name + \"'s type: \" + str(new_series.dtype)))  \n",
    "    print() \n",
    "\n",
    "# the documentation explains that the outcome column can have mainly 4 values: ['arrest', 'citation, 'warning' and 'summons']\n",
    "# we can consider the 'arrest', 'warning' and 'citation' as the result of one hot encoding the outcome column\n",
    "# let's run an integrity check first before proceeding any further\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes = ['arrest', 'citation', 'warning']\n",
    "def outcome_valid(row):\n",
    "    out = row['outcome']\n",
    "    if out not in outcomes:\n",
    "        row['outcome_valid'] = row[outcomes].sum() == 0\n",
    "        return row\n",
    "    \n",
    "    row['outcome_valid'] = ((row[out] == True) and (row[outcomes].sum() == 1)) \n",
    "    return row\n",
    "\n",
    "df = df.apply(outcome_valid, axis=1)\n",
    "non_valid_rows = df[df['outcome_valid'] == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# under the assumption that only one outcome can take place, the nan values in the outcome column should correspond to summons\n",
    "# the non_valid_rows should be dealt with seperately\n",
    "print(non_valid_rows.empty)\n",
    "\n",
    "# the nan value in the outcome column represent summons.\n",
    "df['summons'] = df['outcome'].isna()\n",
    "df = df.fillna('summons')\n",
    "\n",
    "# we can drop either reason_for_stop or raw_BasisForStop as they are equivalent. the latter seems more likely as its values are less expressive\n",
    "df.drop('raw_BasisForStop', axis=1, inplace=True) \n",
    "df['reason_for_stop'] = df['reason_for_stop'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W    344716\n",
      "B     68577\n",
      "H     44046\n",
      "I     12824\n",
      "L      9077\n",
      "O       814\n",
      "N       530\n",
      "Name: raw_OperatorRace, dtype: int64\n",
      "raw_OperatorRace's type: object\n",
      "None\n",
      "\n",
      "M    349446\n",
      "F    131138\n",
      "Name: raw_OperatorSex, dtype: int64\n",
      "raw_OperatorSex's type: object\n",
      "None\n",
      "\n",
      "M    428378\n",
      "W     28840\n",
      "D     14630\n",
      "N      3431\n",
      "A      3332\n",
      "P      1973\n",
      "Name: raw_ResultOfStop, dtype: int64\n",
      "raw_ResultOfStop's type: object\n",
      "None\n",
      "\n",
      "True    480584\n",
      "Name: outcome_valid, dtype: int64\n",
      "outcome_valid's type: bool\n",
      "None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(14, min(19, len(df.columns))):\n",
    "    new_series = pd.Series(df.iloc[:, i])\n",
    "    print(new_series.value_counts())  \n",
    "    print(print(new_series.name + \"'s type: \" + str(new_series.dtype)))  \n",
    "    print() \n",
    "# these columns are to be dropped as they are raw versions of some other columns\n",
    "df = df.iloc[:, :13]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['date', 'time', 'zone', 'race', 'sex', 'department_id', 'arrest',\n",
      "       'citation', 'warning', 'summons', 'frisk_performed',\n",
      "       'search_conducted'],\n",
      "      dtype='object')\n",
      "date                  object\n",
      "time                  object\n",
      "zone                category\n",
      "race                category\n",
      "sex                 category\n",
      "department_id         object\n",
      "arrest                  bool\n",
      "citation                bool\n",
      "warning                 bool\n",
      "summons                 bool\n",
      "frisk_performed         bool\n",
      "search_conducted        bool\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)\n",
    "print(df.dtypes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('ds_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "006414dea9a04848ce797b510a25f3f28ac8668e3d3244e777242cca6bed477f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
