{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Data Preprocessing\n",
    "## Merging DataFrames\n",
    "We need to dictate how the merge takes place: is it an outer join, inner join.Mainly the same analogy as in databases is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame([{\"id\":1 , \"Role\": \"director\"}, {\"id\":2 , \"Role\": \"HR\"}, {\"id\":3 , \"Role\": \"TA\"}, {\"id\":4 , \"Role\": \"professor\"}])\n",
    "df1 = df1.set_index(\"id\")\n",
    "df2 = pd.DataFrame([{\"id\": 7, \"School\":\"Business\"}, {\"id\": 8 , \"School\": \"Law\"},\n",
    "    {\"id\":2 , \"School\": \"Social Sciences\"}, {\"id\":3 , \"School\": \"Artificial Intelligence and Machine Learning\"}])\n",
    "df2 = df2.set_index(\"id\")\n",
    "\n",
    "outer_df = pd.merge(df1, df2, how='outer', left_index=True, right_index=True) # outer join between the two tables\n",
    "print(outer_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inner_df = pd.merge(df1, df2, how='inner', left_index=True, right_index=True) # inner join between the two tables\n",
    "print(inner_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_outer = pd.merge(df1, df2, how='left', left_index=True, right_index=True) \n",
    "print(left_outer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_outer_2 = pd.merge(df2, df1, how='left', left_index=True, right_index=True)\n",
    "print(left_outer_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eventhough the indexes are a natural references when merging, it might not always be the case. Thus, it might be possible to merge according to certain column values using the ***on*** parameter (again as in databases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df1, df2, sep=\"\\n\") # now the indixes are set to the default numerical series\n",
    "# let's add some names and surnames to the dataframes.\n",
    "df1[\"Name\"] = [\"a\", \"b\", \"c\", \"d\"]\n",
    "df2[\"Name\"] = [\"b\", \"e\", \"f\", \"c\"]\n",
    "\n",
    "# del(df1[\"id\"])\n",
    "# del(df2[\"id\"])\n",
    "print(df1, df2, sep=\"\\n\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_name = pd.merge(df1, df2, on=\"Name\", how=\"left\")\n",
    "print(df_name)\n",
    "# let's consider double joining parameters\n",
    "df3 = pd.DataFrame([{\"first_name\": \"a\", \"last_name\": \"la\", \"Role\": \"HR\"},\n",
    " {\"first_name\": \"b\", \"last_name\": \"lb\", \"Role\": \"director\"},{\"first_name\": \"c\", \"last_name\": \"lc\", \"Role\": \"TA\"},\n",
    " {\"first_name\": \"d\", \"last_name\": \"ld\", \"Role\": \"professor\"}])\n",
    "\n",
    "df4 = pd.DataFrame([{\"first_name\": \"a\", \"last_name\": \"la\", \"School\": \"Social Science\"},\n",
    "{\"first_name\": \"b\", \"last_name\": \"x\", \"School\": \"Law\"},\n",
    "{\"first_name\": \"c\", \"last_name\": \"lc\", \"School\": \"Engineering\"}, {\"first_name\": \"f\", \"last_name\": \"la\", \"School\": \"Law\"} ])\n",
    "print(pd.merge(df3, df4, on=[\"first_name\", \"last_name\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas idioms\n",
    "A number of best practices were dictated by this framework's developers as well as users. Pieces of code following such practices are generally referred to as ***pandorable***. The rest of the code will display a number of such idioms\n",
    "### Method chaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's load the census dataset\n",
    "df = pd.read_csv(\"utility_files/census.csv\")\n",
    "\n",
    "# print(df.head())\n",
    "# let's suppose I only need data from the rows where the population estimate at 2010 is larger than 50k while having a SUMLEV == 50\n",
    "# afterwards I am only interested in a set of specific columns while setting the index\n",
    "\n",
    "final_col = [\"POPESTIMATE2010\"]\n",
    "final_col.extend(df.columns[:7])\n",
    "print(final_col)\n",
    "# the pandorian way is to chain the different command as long as the intermediate results are not to be used later\n",
    "better_df = df[(df[\"SUMLEV\"] == 50) & (df[\"POPESTIMATE2010\"] >= 50000)].loc[:, final_col].reset_index()\n",
    "print(better_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## the apply function returns a new pd data structure (series or data frame) with the function passed as parameter applied to every row\n",
    "## in the data structure\n",
    "better_df.columns = [x.lower() for x in better_df.columns]\n",
    "regions = 10\n",
    "divisions = 15\n",
    "state = 50\n",
    "counties = 20\n",
    "print(better_df.head())\n",
    "# I will add to the final data frame a new column with the result of the function: code\n",
    "def code(row) :\n",
    "    return row[\"state\"] * state + row[\"county\"] * counties + row[\"region\"] * regions + row[\"division\"] * divisions\n",
    " \n",
    "better_df[\"code\"] = better_df.apply(lambda x: code(x), axis=1)\n",
    "print(better_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idioms covered here are by no means exclusive. Many of them can be explored through the famous forums such as stackoverflow as well as official documentation \n",
    "\n",
    "## Pandas.Groupby()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the pd.groupby() method is a powerful tool as it splits the dataframe according to a splitting criteria: specified in the paramters\n",
    "# and associate each group with a data frame.\n",
    "df = pd.read_csv(\"utility_files/census.csv\")\n",
    "for group, frame in df.groupby(\"STNAME\"): # split according to the state's name\n",
    "    avg = np.average(frame[\"POPESTIMATE2010\"])\n",
    "    print(\"The average of population in the state \" + str(group) + \" is estimated as \" + str(avg))\n",
    "#  quite efficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it is not always the case that the splitting is purely based on columns' values. A function can be used to split/group the frame\n",
    "# when a function is passed, the default argument considered by the function is the index unless specified otherwise.\n",
    "\n",
    "print(len(df))\n",
    "#let's divide the dataframe into batches of 200 rows\n",
    "def batch_number(index):\n",
    "    return index // 200\n",
    "\n",
    "i = 1\n",
    "for group, frame in df.groupby(batch_number):\n",
    "    # print(group)\n",
    "    print(\"The average population in the batch number {} in the year 2010 is estimated as {}\".format(str(i), str(np.average(frame[\"POPESTIMATE2010\"]))))\n",
    "    i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A point that should be addressed is when there hierarchical index \n",
    "# print(df.head())\n",
    "# let's assume there are multiple indices for example: STNAME and CTYNAME\n",
    "# df = df.set_index([\"STNAME\", \"CTYNAME\"])\n",
    "\n",
    "# for group, frame in df.groupby(level=(0,1)): # this tells Pandas that two rows with a different combination are indeed different\n",
    "# print(group)\n",
    "\n",
    "def grouping_differently(item):\n",
    "    if re.match(\"[A-Ha-h]{1}.*\", item[1]) is not None:\n",
    "        return (item[0], \"A-H city\")\n",
    "    elif re.match(\"[I-Ri-r]{1}.*\", item[1]) is not None:\n",
    "        return (item[0], \"I-R city\")\n",
    "    else:\n",
    "        return (item[0], \"S-Z city\")\n",
    "\n",
    "for group, frame in df.groupby(grouping_differently):\n",
    "    print(group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregation\n",
    "So far no complex preprocessing took place, however, more advanced aggregate functions can take place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's group by the data frame by the name of the city\n",
    "def name_cat(name):\n",
    "    if re.match(\"[A-Ha-h]{1}.*\", name) is not None:\n",
    "        return \"A-H state\"\n",
    "    elif re.match(\"[I-Ri-r]{1}.*\", name) is not None:\n",
    "        return \"I-R state\"\n",
    "    else:\n",
    "        return \"S-Z state\"\n",
    "# after resetting the index, we can group the date according the the state's name\n",
    "# df = df.set_index(\"STNAME\")\n",
    "\n",
    "# print(df.groupby(\"STNAME\")[\"POPESTIMATE2010\"].agg([np.min, np.max, np.mean]))\n",
    "df_states = df.groupby(\"STNAME\").agg({\"POPESTIMATE2010\": [np.min, np.max], \"POPESTIMATE2011\": [np.mean], \"POPESTIMATE2012\":[np.std]}) #\n",
    "# print(df_states[\"POPESTIMATE2010\"][\"amin\"])\n",
    "print(\"\\n\\n\\n\")\n",
    "# print(df_states[\"POPESTIMATE2010\"])\n",
    "\n",
    "def custom_function(series):\n",
    "    return np.sum(series)\n",
    "\n",
    "# any functions can be passed to agg functions as long as they consider the arguements as pandas.series\n",
    "functions_to_apply = [np.min, np.max, np.mean, np.std, custom_function, np.sum]\n",
    "# df.reset_index()\n",
    "\n",
    "df_batch_rank = df.groupby(batch_number).agg({\"POPESTIMATE2010\": functions_to_apply, \"POPESTIMATE2011\": functions_to_apply, \"POPESTIMATE2012\": functions_to_apply})\n",
    "print(df_batch_rank.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pd.transform()\n",
    "This method can be slightly tricky, The method accepts a function referece as an argument, then applies this function to every cell in the data frame / series.\n",
    "The question arises now: what is the difference between pd.apply() and pd.transform() ?\n",
    "Well the function passed to the first is applied to a row of values. As for the second, it is applied to a sole cell value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's consider the airbnb listing dataset\n",
    "df = pd.read_csv(\"utility_files/listings.csv\")\n",
    "# print(df.iloc[50: 60,:]) \n",
    "# print(df.columns)\n",
    "\n",
    "cols = [\"id\", \"name\", \"city\", \"state\", \"bathrooms\", \"bedrooms\", \"beds\", \"square_feet\", \n",
    "\"minimum_nights\", \"maximum_nights\", \"cancellation_policy\", \"review_scores_value\"]\n",
    "df = df[cols]\n",
    "\n",
    "df_state_city_review = df.groupby([\"state\", \"city\"]).agg({\"review_scores_value\": np.nanmean})\n",
    "print(df_state_city_review)\n",
    "\n",
    "def fill_reviews(row):\n",
    "    global df_state_city_review\n",
    "    if np.isnan(row[\"review_scores_value\"]):\n",
    "        row[\"review_scores_value\"] = df_state_city_review.loc[[row[\"state\"],row[\"city\"]], \"review_scores_value\"]\n",
    "    return row\n",
    "\n",
    "\n",
    "df = df.apply(fill_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SCALES\n",
    "\n",
    "* Ratio scale: unit are equally spaced, all mathematical operations are valid: height, weight\n",
    "* Interval Scale: units are equally spaced but there is no true zero: the value zero does not mean the absence of the measured unit\n",
    "it is a meaningful value itself\n",
    "* Ordinal scale: the order matters and the values are not equally spaced: Letter grades: A+, A, A-...\n",
    "* Nominal scale: no order with respect to one another \n",
    "\n",
    "The different scales are of major importance. Pandas allocated certain functionalities to work with scales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_ds = pd.read_csv(\"utility_files/cwurData.csv\")\n",
    "\n",
    "def level_rank(world_rank):\n",
    "    if world_rank <= 100:\n",
    "        return \"first tier\"\n",
    "    elif world_rank <= 200:\n",
    "        return \"second tier\"\n",
    "    elif world_rank <= 300:\n",
    "        return \"third tier\"\n",
    "    else:\n",
    "        return \"other top unis\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_ds[\"Rank_level\"] = uni_ds[\"world_rank\"].apply(level_rank)\n",
    "\n",
    "# print(uni_ds.head())\n",
    "\n",
    "score_per_country_per_tier = uni_ds.pivot_table(values='score', index='country', columns='Rank_level', aggfunc=[np.mean, np.min, np.max])\n",
    "# print(uni_ds[\"score\"])\n",
    "# print(uni_ds.loc[:, [\"institution\", \"score\", \"country\"]].iloc[:30,:])\n",
    "# print(uni_ds[\"score\"][1:20])\n",
    "# print(score_per_country_per_tier.tail())\n",
    "print(score_per_country_per_tier[\"mean\"][\"first tier\"])\n",
    "print(score_per_country_per_tier.iloc[np.argmax(score_per_country_per_tier[\"mean\"][\"first tier\"])])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('ds_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "08488e93894ea7be7272109919d40edb52233f14daf834f5f2387122a81730e1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
