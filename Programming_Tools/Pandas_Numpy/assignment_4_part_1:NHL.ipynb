{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import scipy.stats as stats\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the original data frame\n",
    "nhl_df_org = pd.read_csv(\"utility_files/nhl.csv\")\n",
    "# retrieve only the cities from the wikipedia page\n",
    "cities = pd.read_html(\"utility_files/wiki_data.html\")[1]\n",
    "# retrieve the data of interest\n",
    "cities_org=cities.iloc[:-1,[0,3,5,6,7,8]]\n",
    "print(cities.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as displayed in the previous cell, the columns' names are not practical\n",
    "# data manipulation is needed.\n",
    "cities = cities_org.rename(columns={'Metropolitan area':\"area\", \"Population (2016 est.)[8]\":\"pop\"})\n",
    "# the cities df is a copy of manipulation and further study\n",
    "# convert all column names to lower case and remove unnecessary spaces.\n",
    "cities.columns = pd.Series(cities.columns).apply(lambda x: str(x).lower().strip())\n",
    "print(cities.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cities['nhl'])\n",
    "\n",
    "# as we can see the teams' names require additional preprocessing to remove unnecessary characters\n",
    "\n",
    "# cities_nhl is a dataframe that contain the information related solely to the nhl sport and cities\n",
    "\n",
    "nhl_cols = ['area', 'pop', 'nhl']\n",
    "cities_nhl = cities.copy().loc[:, nhl_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_team_name(name):\n",
    "    # remove anything written between brackets [] \n",
    "    name_1 = re.sub('\\[.*\\]', \"\", name)\n",
    "    # convert to lower case and remove indenting spaces\n",
    "    return name_1.lower().strip()\n",
    "\n",
    "cities_nhl['nhl'] = cities_nhl['nhl'].apply(clean_team_name)\n",
    "# removing non-ascii characters\n",
    "cities_nhl['nhl'] = cities_nhl['nhl'].apply(lambda x: re.sub(\"[^\\x00-\\xFF]\", \"\", x)) \n",
    "# final cleaning step\n",
    "cities_nhl['nhl'] = cities_nhl['nhl'].apply(lambda x: re.sub(\"[^(A-Z)(a-z)\\d\\s]\", \"\", x))\n",
    "\n",
    "# at this point cities with no nhl team are assigned the empty string in the \"nhl\" column\n",
    "# keep the cities with nhl teams\n",
    "cities_nhl = cities_nhl[cities_nhl['nhl'] != ''] \n",
    "print(cities_nhl)\n",
    "# set the index to a numerical series from 0 to the size of the dataframe\n",
    "custom_index = pd.Index(range(len(cities_nhl)))\n",
    "cities_nhl = cities_nhl.set_index(custom_index)\n",
    "\n",
    "## after indexing\n",
    "print()\n",
    "print(\"after indexing\")\n",
    "print(\"##\" * 40)\n",
    "\n",
    "print(cities_nhl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in order to map each team with its area, a new column should be added \n",
    "# that groups both the area/city name as well as the team's name\n",
    "\n",
    "def area_team(row):\n",
    "    area_no_space = re.sub(\"\\s\", \"\", row['area']).strip().lower()\n",
    "    team_no_space = re.sub(\"\\s\", \"\", row['nhl']).strip().lower()\n",
    "    return area_no_space + team_no_space\n",
    "\n",
    "cities_nhl['area_team'] = cities_nhl.apply(area_team, axis=1)\n",
    "print(cities_nhl.loc[:, [\"area\",  \"nhl\", \"area_team\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it is time to consider the nhl DataFrame\n",
    "nhl_org = pd.read_csv(\"utility_files/nhl.csv\")\n",
    "nhl = nhl_org[nhl_org['year'] == year]\n",
    "print(nhl.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# among the columns we are only interested in the team, win (W) and loss (L) columns\n",
    "cols = [\"team\", \"W\", \"L\"]\n",
    "nhl = nhl.loc[:, cols]\n",
    "print(nhl['team'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# at first glance we can detect at least 2 main issues with the team column:\n",
    "# 1. the need for reformatting the names\n",
    "# 2. removing the rows declaring the teams' divisions\n",
    "\n",
    "def clean_team_name_nhl(name):\n",
    "    return re.sub(\"[^(A-z)(a-z)\\d\\s]\", \"\", name).strip().lower()\n",
    "\n",
    "# addressing problem 1\n",
    "nhl['team'] = nhl['team'].apply(clean_team_name_nhl)\n",
    "\n",
    "# addressing problem 2\n",
    "nhl = nhl[~nhl['team'].str.contains(\"division\")]\n",
    "\n",
    "# setting a custom index\n",
    "nhl_custom_index = pd.Index(range(len(nhl)))\n",
    "\n",
    "nhl = nhl.set_index(nhl_custom_index)\n",
    "\n",
    "print(nhl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time to add the area_team name column to the nhl DataFrame\n",
    "nhl['area_team'] = nhl['team'].apply(lambda x: re.sub(\"\\s\",\"\", x).strip().lower())\n",
    "print(nhl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective is to map every team in the nhl dataframe to an area/city in the cities_nhl dataframe. The first step is to merge the two dataframes on the area_team column assigning most of the teams. The rest should be processed separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# having the area_team column  in common between the two DataFrames we can merge them\n",
    "\n",
    "merge_areas = pd.merge(cities_nhl, nhl, how ='left',on=['area_team'])\n",
    "print(merge_areas.loc[:, [\"area\", \"team\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_teams = pd.merge(nhl, cities_nhl, how='left', on=['area_team'])\n",
    "print(merge_teams.loc[:, [\"team\", \"area\",\"area_team\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams_no_clear_area = merge_teams[merge_teams['area'].isna()]\n",
    "print(teams_no_clear_area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "areas_no_clear_team = merge_areas[merge_areas[\"team\"].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the teams left out with no clear area name are to be processed manually\n",
    "# first let's consider the possibility of a mapping between the column [area_team] in the nhl DF\n",
    "# and the column [area_team] in the nhl_cities DF\n",
    "\n",
    "area_team_no_match_nhl_DF = teams_no_clear_area.set_index(pd.Index(range(len(teams_no_clear_area))))['area_team']\n",
    "area_team_no_match_cities_nhl_DF = areas_no_clear_team.set_index(pd.Index(range(len(areas_no_clear_team))))['area_team']\n",
    "\n",
    "no_match = pd.DataFrame({\"team_no_area\": area_team_no_match_nhl_DF, \"area_no_name\": area_team_no_match_cities_nhl_DF})\n",
    "print(no_match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the last dataframe made it easy to see the mapping betweent the two columns\n",
    "# the following dictionary reflects the mapping\n",
    "\n",
    "mapping = {\"newyorkcityrangersislandersdevils\": \"newyorkislanders\", \"losangeleskingsducks\": \"losangeleskings\", \"dallas–fortworthstars\":\"dallasstars\"\n",
    ", 'washington,d.c.capitals': \"washingtoncapitals\", \"minneapolis–saintpaulwild\": \"minnesotawild\", \"denveravalanche\": \"coloradoavalanche\"\n",
    ", \"miami–fortlauderdalepanthers\": \"floridapanthers\", \"tampabayarealightning\": \"tampabaylightning\", \"st.louisblues\": \"stlouisblues\"\n",
    ", \"lasvegasgoldenknights\": \"vegasgoldenknights\", \"phoenixcoyotes\": \"arizonacoyotes\", \"raleighhurricanes\": \"carolinahurricanes\", \"sanfranciscobayareasharks\": \"sanjosesharks\"}\n",
    "\n",
    "# the next step is to map the old area_team names in the cities_nhl DF to their respective mapped value  \n",
    "\n",
    "cities_nhl['area_team'] = cities_nhl['area_team'].apply(lambda x: mapping[x].strip() if x in mapping else x)\n",
    "\n",
    "merge_teams = pd.merge(nhl, cities_nhl, how='left', on=['area_team'])\n",
    "print(merge_teams.loc[: , ['area', 'team', 'area_team']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as expected there are 3 teams with no associated area, the next stop now is to associate these teams with one\n",
    "# of areas provided. This task requires more human understanding of the data and a little bit of research\n",
    "\n",
    "print(\"LEFT OUT TEAMS\")\n",
    "print(merge_teams[merge_teams['area'].isna()]['team'])\n",
    "print()\n",
    "print(\"AREAS:\")\n",
    "print(cities_nhl['area'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Research Results\n",
    "According to the following [link](https://en.wikipedia.org/wiki/New_Jersey_Devils), the ***new jersey devils*** can be assigned to the ***New York City***. The ***new york rangers*** are also assigned to the same area. As for ***anaheim ducks***, it belongs to the ***Los Angelos*** area according to the following links:\n",
    "* [link1](https://en.wikipedia.org/wiki/Anaheim_Ducks#:~:text=Anaheim%20Ducks%20The%20Anaheim%20Ducks%20are%20a%20professional,and%20play%20their%20home%20games%20at%20Honda%20Center.)\n",
    "* [link2](https://en.wikipedia.org/wiki/Anaheim,_California)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_area = {\"new jersey devils\": \"New York City\", \"new york rangers\": \"New York City\", \"anaheim ducks\": \"Los Angeles\"}\n",
    "\n",
    "def set_areas(row):\n",
    "    if row['team'] in team_area:\n",
    "        row['area'] = team_area[row['team']]\n",
    "    return row\n",
    "merge_teams = merge_teams.apply(set_areas, axis=1)\n",
    "\n",
    "print(merge_teams.loc[: , ['area', 'team', 'area_team']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Step\n",
    "As the dataframe is cleaned, merged and filled with the necessary values, we can proceed to the final step which is\n",
    "compute the win-loss ration for each team, then group the team by the area and consider the correlation between the win-loss values and the area's population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = merge_teams.loc[:, ['area', 'team', 'W', 'L', 'pop']]\n",
    "final_df['win_loss_ratio'] = final_df['W'].astype(float) / (final_df['W'].astype(float) + final_df['L'].astype(float))\n",
    "final_df = final_df.loc[:, ['area', 'win_loss_ratio', 'pop']]\n",
    "# print(final_df)\n",
    "\n",
    "final_df = final_df.set_index('area').astype(float).groupby('area').agg({\"win_loss_ratio\":'mean', 'pop':'mean'})\n",
    "print(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_df.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv(\"/home/ayhem18/Ayhem18/DEV/Data_science/Towards_Data_science/Programming_Tools/Pandas_Numpy/nhl_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('ds_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "08488e93894ea7be7272109919d40edb52233f14daf834f5f2387122a81730e1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
