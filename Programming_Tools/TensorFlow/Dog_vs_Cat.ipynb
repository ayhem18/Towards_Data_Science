{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "main_directory = \"utility_files/dog_vs_cat_ds\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_zip = \"/\".join([main_directory, \"test1.zip\"])\n",
    "train_zip = \"/\".join([main_directory, \"train.zip\"])\n",
    "\n",
    "#unzip training data\n",
    "zip_ref = zipfile.ZipFile(train_zip, 'r')\n",
    "zip_ref.extractall(main_directory + '/train')\n",
    "zip_ref.close()\n",
    "# unzip test data\n",
    "\n",
    "zip_ref = zipfile.ZipFile(test_zip, 'r')\n",
    "zip_ref.extractall(main_directory + '/test')\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# since the folder with the data contains an additional folder, we will move the images from the current folder \n",
    "# to either the cat_train or train_dog folders (are to be created)\n",
    "\n",
    "train_dog = \"/\".join([main_directory, \"train\", \"dog\"])\n",
    "train_cat = \"/\".join([main_directory, \"train\", \"cat\"])\n",
    "\n",
    "\n",
    "# os.mkdir(train_dog)\n",
    "# os.mkdir(train_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's move each training label to the corresponding folder\n",
    "\n",
    "train_dir_name = \"/\".join([main_directory, \"train\"])\n",
    "train_dir = os.path.join(train_dir_name + \"/train\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for file in os.listdir(train_dir):\n",
    "    des = \"\"\n",
    "    if \"cat\" in file.lower().strip():\n",
    "        des = train_cat\n",
    "    elif \"dog\" in file.lower().strip():\n",
    "        des = train_dog\n",
    "    \n",
    "    source = \"/\".join([train_dir_name,\"train\", file])\n",
    "    destination = \"/\".join([des, file])\n",
    "    # print(source, destination, sep=\"\\n\")\n",
    "\n",
    "    shutil.move(source, destination)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# delete the old train folder\n",
    "os.rmdir(\"/\".join([main_directory, \"train\", \"train\"]))\n",
    "# after diving the images into the corresponding directories, it would easier to use tensorflow's Datagenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_names = os.listdir(train_dog)\n",
    "cat_names = os.listdir(train_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Parameters for our graph; we'll output images in a 4x4 configuration\n",
    "nrows = 4\n",
    "ncols = 4\n",
    "\n",
    "pic_index = 0 # Index for iterating over images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up matplotlib fig, and size it to fit 4x4 pics\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(ncols*4, nrows*4)\n",
    "\n",
    "pic_index+=8\n",
    "\n",
    "next_cat_pix = [os.path.join(train_cat, fname) \n",
    "                for fname in cat_names[ pic_index-8:pic_index] \n",
    "               ]\n",
    "\n",
    "next_dog_pix = [os.path.join(train_dog, fname) \n",
    "                for fname in dog_names[ pic_index-8:pic_index]\n",
    "               ]\n",
    "\n",
    "for i, img_path in enumerate(next_cat_pix+next_dog_pix):\n",
    "  # Set up subplot; subplot indices start at 1\n",
    "  sp = plt.subplot(nrows, ncols, i + 1)\n",
    "  sp.axis('Off') # Don't show axes (or gridlines)\n",
    "\n",
    "  img = mpimg.imread(img_path)\n",
    "  plt.imshow(img)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_input_shape = (150, 150, 3) # image of 150 * 150 pixels with 3 bytes for colors\n",
    "\n",
    "# this model is taken out of the fashion_mnist_CNN notebook\n",
    "import tensorflow.keras.layers as tfl\n",
    "\n",
    "def cnn_fashion_model(input_shape, num_classes):\n",
    "    # define the input\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    # relu activation is used extensively:\n",
    "    relu = tfl.ReLU()\n",
    "    # 2D convolutional layer\n",
    "    f1 = 16\n",
    "    size1  = (3, 3)\n",
    "    conv1 = tfl.Conv2D(filters=f1, kernel_size=size1, strides=(2, 2), padding='same')\n",
    "    \n",
    "    pool1 = tfl.MaxPool2D((2, 2))\n",
    "    f2 = 32\n",
    "    conv2 = tfl.Conv2D(filters=f2, kernel_size=size1, strides=(1, 1), padding='same')\n",
    "    \n",
    "    # normalize the input on the the channels axis\n",
    "    batnor = tfl.BatchNormalization(axis=3)\n",
    "    size2 = (3, 3)\n",
    "    f3 = 64\n",
    "    conv3 = tfl.Conv2D(filters=f3, kernel_size=size2, strides=(2, 2), padding='same')\n",
    "\n",
    "    f4 = 64\n",
    "    conv4 = tfl.Conv2D(filters=f4, kernel_size=size2, strides=(1, 1), padding='same')\n",
    "\n",
    "    pool2 = tfl.MaxPool2D((2, 2))\n",
    "\n",
    "    # the neural network should be as follows:\n",
    "    # con1 * 2 -> conv2 *2 -> pool1 -> conv3 * 2 -> conv4 * 2 -> pool2 -> fully connected1 -> fullyconnected2 -> softmax\n",
    "    x = conv1(inputs)\n",
    "    x = relu(x)\n",
    "\n",
    "    x = conv2(inputs)\n",
    "    x = relu(x)\n",
    "\n",
    "\n",
    "    x = tfl.BatchNormalization(axis=3)(x)\n",
    "    x = pool1(x)\n",
    "    \n",
    "    x = conv3(x)\n",
    "    x = relu(x)\n",
    "\n",
    "    x = conv4(x)\n",
    "    x = relu(x)\n",
    "\n",
    "    x = tfl.BatchNormalization(axis=3)(x)\n",
    "    x = pool2(x)\n",
    "\n",
    "    flatten = tfl.Flatten() \n",
    "    fc1 = tfl.Dense(128, activation='relu')\n",
    "    fc2 = tfl.Dense(128, activation='relu')\n",
    "    \n",
    "    # the last layer depends mainly on the number of classes\n",
    "    output_units = num_classes if num_classes > 2 else 1\n",
    "    activation = \"sigmoid\" if output_units == 1 else \"softmax\"\n",
    "    \n",
    "    fc3 = tfl.Dense(output_units, activation=activation)\n",
    "\n",
    "    x = flatten(x)\n",
    "    x = fc1(x)\n",
    "    x = fc2(x)\n",
    "    outputs = fc3(x)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_model = cnn_fashion_model(model_input_shape, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "image_size = (150, 150)\n",
    "train_dir = os.path.join(\"/\".join([main_directory, \"train\"]))\n",
    "# All images will be rescaled by 1./255.\n",
    "train_datagen = ImageDataGenerator( rescale = 1.0/255)\n",
    "\n",
    "# --------------------\n",
    "# Flow training images in batches of 20 using train_datagen generator\n",
    "# --------------------\n",
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                                                    batch_size=20,\n",
    "                                                    class_mode='binary',\n",
    "                                                    target_size=image_size)     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.keras.losses.BinaryCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "metrics = ['accuracy']\n",
    "our_model.compile(loss=loss, optimizer=optimizer, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = our_model.fit(\n",
    "            train_generator,\n",
    "            epochs=15,\n",
    "            verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('ds_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "08488e93894ea7be7272109919d40edb52233f14daf834f5f2387122a81730e1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
