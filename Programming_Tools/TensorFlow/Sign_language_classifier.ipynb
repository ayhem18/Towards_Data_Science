{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CuC5GYRt1_3w"
      },
      "source": [
        "## Overview\n",
        "This notebook contains a Deep Learning model to classify the signs associated with each of the English alphabetic letters. The training as well as testing sets are provided in [Kaggle Platform](https://www.kaggle.com/datasets/datamunge/sign-language-mnist) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W5EOBDt31_34"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd \n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-TPzCP0I1_3-"
      },
      "outputs": [],
      "source": [
        "main_directory = os.path.join(\"utility_files\", \"Sign_language_MNIST\") # the root directory for the data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hesF0oSI1_4A"
      },
      "source": [
        "### Setting the directories \n",
        "The dataset is provided in Kaggle in an zip file. The datasets then should be extracted. The few cells below execute this process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KBGZmTJY1_4C"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "initial_archive_name = \"archive.zip\"\n",
        "archive_zip = os.path.join(main_directory, initial_archive_name)\n",
        "if os.path.exists(archive_zip):\n",
        "    zip_ref = zipfile.ZipFile(archive_zip, 'r')\n",
        "    zip_ref.extractall(main_directory)\n",
        "    zip_ref.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jErpi3Ey1_4D"
      },
      "outputs": [],
      "source": [
        "TRAINING_DIR_NAME = \"sign_mnist_train\"\n",
        "TESTING_DIR_NAME = \"sign_mnist_test\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dn3NrVt91_4F",
        "outputId": "1206c1f6-6656-448c-b134-39588eec6c4a"
      },
      "outputs": [],
      "source": [
        "# removing all files / directries that are neither training or testing set\n",
        "# from genericpath import isdir\n",
        "\n",
        "# for file in os.listdir(main_directory):    \n",
        "#     if file not in [TRAINING_DIR_NAME, TESTING_DIR_NAME]:\n",
        "#         file_name = os.path.join(main_directory, file)\n",
        "#         if os.path.isfile(file_name):\n",
        "#             os.remove(file_name)\n",
        "#         elif os.path.isdir(file_name):\n",
        "#             os.rmdir(file_name)\n",
        "\n",
        "print(os.listdir(main_directory))   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ibGH7SYd1_4K"
      },
      "source": [
        "### Working with the training files\n",
        "After removing the unnecessary directories, it is time to understand the data provided and perform the necessary data preprocessing before creating any model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h3LR2gov1_4M"
      },
      "outputs": [],
      "source": [
        "TRAIN_DIR = os.path.join(main_directory, TRAINING_DIR_NAME)\n",
        "TEST_DIR = os.path.join(main_directory, TESTING_DIR_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvbffQeM1_4O",
        "outputId": "b385e0a2-a0bb-497b-84b9-95702881e113"
      },
      "outputs": [],
      "source": [
        "# print the content of the trianing diretory\n",
        "print(os.listdir(TRAIN_DIR))\n",
        "print(os.listdir(TEST_DIR))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MhYvTDB_1_4P"
      },
      "outputs": [],
      "source": [
        "## the data is stored in a csv which might call to the use of the pandas library\n",
        "import pandas as pd\n",
        "train_file = os.path.join(TRAIN_DIR, os.listdir(TRAIN_DIR)[0])\n",
        "train_df_org = pd.read_csv(train_file) \n",
        "\n",
        "test_file = os.path.join(TEST_DIR, os.listdir(TEST_DIR)[0])\n",
        "test_df_org = pd.read_csv(test_file)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ioaLmpM1_4Q",
        "outputId": "32bd59d2-63a3-40ea-bd86-d20cc91f6c4f"
      },
      "outputs": [],
      "source": [
        "print(train_df_org.shape)\n",
        "# so we can see we have 785 columns and 27455 training samples\n",
        "print(train_df_org.columns)\n",
        "# as we can see the first picture is the label while the rest represent numerical values of the individual pixels\n",
        "\n",
        "new_cols_name = {}\n",
        "new_cols_name['label'] = \"y\"\n",
        "for i in range(1, 785):\n",
        "    new_cols_name[\"pixel{}\".format(str(i))] = str(i)\n",
        "train_df = train_df_org.rename(columns=new_cols_name)\n",
        "test_df = test_df_org.rename(columns=new_cols_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cXISZvnB1_4S"
      },
      "outputs": [],
      "source": [
        "y_train = train_df[\"y\"]\n",
        "train_df.drop(\"y\", inplace=True,axis=1)\n",
        "# print(train_df.columns) \n",
        "\n",
        "y_test = test_df[\"y\"]\n",
        "test_df.drop(\"y\", inplace=True,axis=1)\n",
        "# print(train_df.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aOuCYUbd1_4T"
      },
      "outputs": [],
      "source": [
        "img_size = (28, 28, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jjBpp9I41_4U"
      },
      "outputs": [],
      "source": [
        "# according to the data documentation, the images are meant to be 28 * 28 gray scale images\n",
        "pixel_range = 255.0\n",
        "def transform_row_to_pic(df, index):\n",
        "    return df.iloc[i, :].values.reshape(img_size) / pixel_range"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "id": "Mc6QGyfk1_4W",
        "outputId": "a285a27a-6890-46c6-9428-b88bde6f8a0b"
      },
      "outputs": [],
      "source": [
        "import string\n",
        "import random\n",
        "## Visualization\n",
        "sample = 20\n",
        "  \n",
        "plt.figure(figsize=(10, 10))\n",
        "for i in range(sample):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    index = random.randint(0, len(train_df))\n",
        "    plt.imshow(transform_row_to_pic(train_df, index), cmap=plt.cm.binary)\n",
        "    plt.xlabel(string.ascii_letters[y_train[index]]) # the numerical label associated with the hand sign is the letter's order in the alphabet\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "id": "T_k5_ER7TcHf",
        "outputId": "6075e2a6-a9a7-4412-fd3c-58dd49104b7f"
      },
      "outputs": [],
      "source": [
        "for i in range(sample):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    index = random.randint(0, len(test_df))\n",
        "    plt.imshow(transform_row_to_pic(test_df, index), cmap=plt.cm.binary)\n",
        "    plt.xlabel(string.ascii_letters[(y_test[index])]) # the numerical label associated with the hand sign is the letter's order in the alphabet\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5q0h_NTW1_4X"
      },
      "outputs": [],
      "source": [
        "def df_to_X(df):\n",
        "    \"\"\"This method coverts the training dataframe to \"\"\"\n",
        "    return np.array([df.iloc[i, :].values / pixel_range for i in range(len(df))])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7UoqrWD1_4Y",
        "outputId": "e28a1a37-e1b1-4182-b54b-c4464b364299"
      },
      "outputs": [],
      "source": [
        "X_train = df_to_X(train_df)\n",
        "Y_train = y_train.values\n",
        "print(X_train[:3])\n",
        "\n",
        "X_test = df_to_X(test_df)\n",
        "Y_test = y_test.values\n",
        "print(X_test[:3])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qh2Y-4JwQerx"
      },
      "outputs": [],
      "source": [
        "# create a validation data set\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "val_size = 0.2\n",
        "random_state = 11\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(X_train, y_train, test_size=val_size, random_state=random_state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ypk21D1dnkHT"
      },
      "outputs": [],
      "source": [
        "X_train_img = np.array([np.reshape(row,(28, 28, 1)) for row in X_train])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y3ZQ__wZ1_4Y"
      },
      "outputs": [],
      "source": [
        "# DL models imports\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.layers as tfl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJAjsMsp6Gn0"
      },
      "source": [
        "### Data Augmentation\n",
        "We need to experiement with data augmentation: mainly cropping and reflecting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iy5_IZxynqFK"
      },
      "outputs": [],
      "source": [
        "from tensorflow.image import flip_left_right\n",
        "from tensorflow.image import central_crop\n",
        "from tensorflow.image import resize\n",
        "from tensorflow.python.ops.numpy_ops import np_config\n",
        "np_config.enable_numpy_behavior()\n",
        "\n",
        "def augmented_image(image, t=0.5, central_frac=0.8, res=True):\n",
        "    p = random.random()\n",
        "    new_image = None\n",
        "    if p > t:\n",
        "        new_image =  central_crop(image, central_fraction=0.8)\n",
        "    else:\n",
        "        new_image = flip_left_right(image)\n",
        "    if res:\n",
        "        return resize(new_image, [image.shape[0], image.shape[1]], method=\"nearest\")\n",
        "    return new_image\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train_aug = np.array([augmented_image(image).reshape((-1, )) for image in X_train_img])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_XDTvBiyAjz",
        "outputId": "55c674ba-e42e-4be0-85e0-22cab1f6a5d8"
      },
      "outputs": [],
      "source": [
        "print(len(X_train_aug))\n",
        "print(len(X_train))\n",
        "print(X_train_aug.shape)\n",
        "print(X_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XQldIjgpuTha"
      },
      "outputs": [],
      "source": [
        "X_train_final = np.append(X_train, X_train_aug, axis=0)\n",
        "Y_train_final = np.append(Y_train, Y_train, axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gEHz34FNuYcL",
        "outputId": "a5a42bcd-4193-421c-bcab-3744bdc801d1"
      },
      "outputs": [],
      "source": [
        "print(len(X_train_final))\n",
        "print(len(Y_train_final))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTev3ffQ3NDx"
      },
      "source": [
        "## Models\n",
        "In this part of the notebook, I will try to consider different models, optimize each of them starting from Plain Neural networks to plain CNN, CNN with Residual blocks, and finally a model based on transfer learning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WWiXAXhn1_4Z"
      },
      "source": [
        "### Plain Neural Networks \n",
        "So the first approach to solve this problem is to use Plain neural networks that uses all of the bytes in each picture. The main goal is to achieve as high of a performance as possible with each available model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HKl7hQ2z1_4a"
      },
      "outputs": [],
      "source": [
        "# build the model: \n",
        "#input_shape = (1, 784)\n",
        "first_model = tf.keras.Sequential([\n",
        "    # tfl.Flatten(input_shape=input_shape),\n",
        "    tfl.Dense(1024, activation='relu'), \n",
        "    tfl.Dense(1024, activation='relu'), \n",
        "    tfl.BatchNormalization(), \n",
        "    tfl.Dense(512, activation='relu'), \n",
        "    tfl.Dense(512, activation='relu'),\n",
        "    tfl.BatchNormalization(),\n",
        "    tfl.Dense(256, activation='relu'), \n",
        "    tfl.Dense(128, activation='relu'),\n",
        "    tfl.BatchNormalization(),\n",
        "    tfl.Dense(64, activation='relu'),\n",
        "    tfl.Dense(32, activation='relu'), \n",
        "    tfl.BatchNormalization(),  \n",
        "    tfl.Dense(26, activation='softmax')] # output layer\n",
        "    ) \n",
        "\n",
        "# compile the model\n",
        "EPOCHS = 15\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CjzFlAW31_4b",
        "outputId": "c5635302-c626-4404-a4f1-66a4541db824"
      },
      "outputs": [],
      "source": [
        "first_model.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False), metrics=['accuracy'])\n",
        "# history_aug = first_model.fit(X_train_final, Y_train_final, epochs=EPOCHS, validation_data=(X_val, Y_val))\n",
        "# print(first_model.evaluate(X_test, y_test))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xr_JeaCk1_4b"
      },
      "outputs": [],
      "source": [
        "# acc = history_aug.history['accuracy']\n",
        "# val_acc = history_aug.history['val_accuracy']\n",
        "# loss = history_aug.history['loss']\n",
        "# val_loss = history_aug.history['val_loss']\n",
        "\n",
        "# epochs = range(len(acc))\n",
        "\n",
        "# plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "# plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "# plt.title('Training and validation accuracy')\n",
        "# plt.legend(loc=0)\n",
        "# plt.figure()\n",
        "\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l6dBxiTKBbiB"
      },
      "outputs": [],
      "source": [
        "def dnn_with_dropout():\n",
        "    model = tf.keras.Sequential([\n",
        "    tfl.Dense(1024, activation='relu'),\n",
        "    tfl.Dropout(0.4),\n",
        "    \n",
        "    tfl.Dense(1024, activation='relu'),\n",
        "    tfl.BatchNormalization(axis=-1), \n",
        "    tfl.Dropout(0.4),\n",
        "\n",
        "    tfl.Dense(512, activation='relu'),\n",
        "    tfl.Dropout(0.2),\n",
        "\n",
        "    tfl.Dense(512, activation='relu'),\n",
        "    tfl.BatchNormalization(axis=-1), \n",
        "    tfl.Dropout(0.2),\n",
        "    \n",
        "    tfl.Dense(256, activation='relu'),\n",
        "    tfl.Dropout(0.1),\n",
        "    \n",
        "    tfl.Dense(128, activation='relu'),\n",
        "    tfl.BatchNormalization(axis=-1),\n",
        "    tfl.Dropout(0.05),\n",
        "\n",
        "    tfl.Dense(64, activation='relu'),    \n",
        "    tfl.Dense(26, activation='softmax')]) # output layer\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0105Shd-CJ-D"
      },
      "outputs": [],
      "source": [
        "second_model = dnn_with_dropout()\n",
        "second_model.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False), metrics=['accuracy'])\n",
        "history_aug = second_model.fit(X_train_final, Y_train_final, epochs=EPOCHS, validation_data=(X_val, Y_val))\n",
        "print(second_model.evaluate(X_test, Y_test))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def dnn_with_l2(input_shape=(784, )):\n",
        "    inputs = tfl.Input(shape=input_shape)\n",
        "    X = tfl.Dense(1024, activation='relu', kernel_regularizer='l2')(inputs)\n",
        "    X = tfl.Dense(1024, activation='relu', kernel_regularizer='l2')(X) \n",
        "    X = tfl.BatchNormalization(axis=-1)(X) \n",
        "    X = tfl.Dense(512, activation='relu', kernel_regularizer='l2')(X)\n",
        "\n",
        "    X = tfl.Dense(512, activation='relu', kernel_regularizer='l2')(X)\n",
        "    X = tfl.BatchNormalization(axis=-1)(X)\n",
        "    X = tfl.Dense(256, activation='relu', kernel_regularizer='l2')(X)\n",
        "    \n",
        "    X = tfl.Dense(128, activation='relu', kernel_regularizer='l2')(X)\n",
        "    X = tfl.BatchNormalization(axis=-1)(X)\n",
        "    \n",
        "    X = tfl.Dense(64, activation='relu', kernel_regularizer='l2')(X)   \n",
        "    outputs = tfl.Dense(26, activation='softmax')(X) # output layer\n",
        "    \n",
        "    return tf.keras.Model(inputs, outputs)    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "third_model = dnn_with_l2()\n",
        "third_model.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False), metrics=['accuracy'])\n",
        "third_model.fit(X_train_final, Y_train_final)\n",
        "print(third_model.evaluate(X_test, Y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## TRAIN / TEST similarity\n",
        "The models created so far perform remarkably well on the validation set while having modest results on the test set. This raises the possibility of having inheritent characteristics / features in the test set that are simply absent in the training dataset. It might be worthwhile exploring this possibility."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## first let's check out manually the optimal central portion of the image: as 784 features might represent a challenge to any model\n",
        "\n",
        "sample = 20\n",
        "\n",
        "u_lab = np.unique(y_train.values)\n",
        "occ = np.zeros(np.max(u_lab)) - 1\n",
        "print(occ)\n",
        "count = 0\n",
        "i = 0\n",
        "print(u_lab)\n",
        "\n",
        "u_lab_test = np.unique(y_test.values)\n",
        "print(u_lab_test)\n",
        "\n",
        "while count < len(u_lab):\n",
        "    if occ[y_train[i] - 1] == -1:\n",
        "        occ[y_train[i] - 1] += i\n",
        "        count += 1\n",
        "    i += 1\n",
        "\n",
        "occ = occ.astype(int)\n",
        "print(occ)\n",
        "  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(30, 30))\n",
        "for i in range(len(occ))[:5]:\n",
        "    index = occ[i]\n",
        "    if index != -1 :\n",
        "        plt.subplot(5,5, i+1)\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "        plt.grid(False)\n",
        "        plt.imshow(augmented_image(transform_row_to_pic(train_df, index) * 255.0, t=0.0, central_frac=0.9, res=False), cmap=plt.cm.binary)\n",
        "        \n",
        "        plt.xlabel(string.ascii_letters[y_train[index]]) # the numerical label associated with the hand sign is the letter's order in the alphabet\n",
        "\n",
        "plt.show()\n",
        "plt.figure(figsize=(30, 30))\n",
        "\n",
        "for i in range(len(occ))[:5]:\n",
        "    index = occ[i]\n",
        "    if index != -1 :\n",
        "        plt.subplot(5,5, i+1)\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "        plt.grid(False)\n",
        "        plt.imshow(transform_row_to_pic(train_df, index) * 255.0, cmap=plt.cm.binary)\n",
        "        plt.xlabel(string.ascii_letters[y_train[index]]) # the numerical label associated with the hand sign is the letter's order in the alphabet\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# as we can see a central crop of  90% is good enough.\n",
        "\n",
        "train_df['y'] = pd.Series([1 for _ in range(len(train_df))])\n",
        "test_df['y'] = pd.Series(0 for _ in range(len(test_df)))\n",
        "all_data = pd.concat([train_df, test_df])\n",
        "all_data_y = all_data['y']\n",
        "all_data = all_data.drop(\"y\", axis=1)\n",
        "all_data = np.array([augmented_image(transform_row_to_pic(all_data, i), t=0.0, central_frac=0.9, res=False).reshape(24, 24) \\\n",
        "for i in range(len(all_data))])\n",
        "print(all_data[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "all_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_X_train, data_X_test, data_y_train, data_y_test = \\\n",
        "train_test_split(all_data, all_data_y.values, test_size=0.2, random_state=random_state, stratify=all_data_y.values)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## let's consider a powerful model\n",
        "\n",
        "similarity_model = tf.keras.Sequential([\n",
        "    # tfl.Flatten(input_shape=input_shape),\n",
        "    tfl.Flatten(),\n",
        "    tfl.Dense(1024, activation='relu'), \n",
        "    tfl.Dense(1024, activation='relu'), \n",
        "    tfl.BatchNormalization(), \n",
        "    tfl.Dense(512, activation='relu'), \n",
        "    tfl.Dense(512, activation='relu'),\n",
        "    tfl.BatchNormalization(),\n",
        "    tfl.Dense(256, activation='relu'), \n",
        "    tfl.Dense(128, activation='relu'),\n",
        "    tfl.BatchNormalization(),\n",
        "    tfl.Dense(64, activation='relu'),\n",
        "    tfl.Dense(32, activation='relu'), \n",
        "    tfl.BatchNormalization(),  \n",
        "    tfl.Dense(1, activation='sigmoid')]) # output layer \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "similarity_model.compile(optimizer='adam', metrics=['acc', tf.keras.metrics.AUC()], loss=tf.keras.losses.BinaryCrossentropy())\n",
        "similarity_model.fit(data_X_train, data_y_train, epochs=10)\n",
        "print(similarity_model.evalutate(data_X_test, data_y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Convolutional Neural Networks\n",
        "For image recognition problems. Convolutional Neural Networks represent more powerful solutions as they extract features out of pictures and use to classify images properly."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Sign_language_classifier.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.4 ('ds_env')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "08488e93894ea7be7272109919d40edb52233f14daf834f5f2387122a81730e1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
