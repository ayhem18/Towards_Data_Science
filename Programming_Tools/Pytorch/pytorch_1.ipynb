{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "This notebook was created to save and track my Pytorch learning Journey. This notebook is likely to have multiple sequels as this Pytorch is quite a complex and sophisticated framework"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fundamentals"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "install CUDA on your local machine if a GPU is available. Don't forget to google cuda is still not available!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tensors"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "starting with some theory ? what is a tensor ?  \n",
    "Well, first assuming the existence of a basis of $n$ vectors. then a tensor of rank $m$ is a quantity that is defined by $n^m$ components. Generally this quantity represents a phenomena that can be mathematically modeled by $m$ different vectors. Each component represents a scalar associated with a combination among the possible combinations of choosing $n$ directions (from the basis vectors) $m$ times with repetition.  \n",
    "HERE IS  A GREAT [REFERENCE](https://www.youtube.com/watch?v=f5liqUk0ZTw)  \n",
    "resources:  \n",
    "1. [torch.tensor](https://pytorch.org/docs/stable/tensors.html)\n",
    "2. [ZTM course](https://www.learnpytorch.io/00_pytorch_fundamentals/)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nevertheless, let's get more acquainted with tensors in ***Pytorch***   \n",
    "1. a scalar is a tensor of dimension $0$\n",
    "2. a vector is a tensor of dimension $1$\n",
    "3. a matrix is a tensor of dimension $2$\n",
    "4. an image is a tensor of dimension $3$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 3])\n",
      "3\n",
      "tensor([[0.0759, 0.0145, 0.6034, 0.7342],\n",
      "        [0.3004, 0.5141, 0.2457, 0.6696],\n",
      "        [0.2699, 0.0861, 0.0877, 0.2000]])\n",
      "tensor([[[0.8396, 0.7654, 0.2743, 0.3086],\n",
      "         [0.7247, 0.2554, 0.0491, 0.5630],\n",
      "         [0.3756, 0.2225, 0.5597, 0.0028]],\n",
      "\n",
      "        [[0.1691, 0.5789, 0.5650, 0.5662],\n",
      "         [0.5461, 0.4812, 0.9157, 0.7639],\n",
      "         [0.5184, 0.0495, 0.8166, 0.4469]]])\n"
     ]
    }
   ],
   "source": [
    "# Tensor\n",
    "t = torch.tensor([[[1, 2, 3],\n",
    "                        [3, 6, 9],\n",
    "                        [2, 4, 5]], \n",
    "                [[1, 2, 3], \n",
    "                 [1, 1, 1],\n",
    "                  [2,2,2]]])\n",
    "\n",
    "print(t.shape)\n",
    "print(t.ndim)\n",
    "\n",
    "# creating tensors is not usually done manuallym\n",
    "# here is some good tensor-creation methos\n",
    "t1 = torch.rand(size=(3, 4))\n",
    "t2 = torch.rand(size=(2, 3, 4))\n",
    "\n",
    "print(t1)\n",
    "print(t2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of tensor: torch.Size([2, 2, 2])\n",
      "data type of tensor: torch.float32\n",
      "the device where the tensor is stored: cpu\n"
     ]
    }
   ],
   "source": [
    "ones1 = torch.ones(size=(3, 1))\n",
    "ones2 = torch.ones(size=(3, 2))\n",
    "# print(ones1, ones2, sep='\\n')\n",
    "\n",
    "# let's create some tensor and extract its characteristics\n",
    "t = torch.rand(size=(2, 2, 2))\n",
    "print(f\"shape of tensor: {t.shape}\")\n",
    "print(f\"data type of tensor: {t.dtype}\")\n",
    "print(f\"the device where the tensor is stored: {t.device}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of runtime errors would probably be cause by a mismatch of ones of these fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 2.],\n",
      "        [2., 2.],\n",
      "        [2., 2.]])\n",
      "tensor([[9., 9.],\n",
      "        [9., 9.],\n",
      "        [9., 9.]])\n"
     ]
    }
   ],
   "source": [
    "# as for operations with matrices, they are the same as in python, numpy\n",
    "print(ones1 + ones2) # broadcasting works here\n",
    "print((ones1 + 1) * (ones2 + 3.5)) # should have a (3, 2) with 9.0 for each value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1])\n",
      "tensor([[-0.5425,  0.2715, -0.0266, -0.2744],\n",
      "        [-0.3252,  0.2417, -1.5869, -0.6758],\n",
      "        [ 0.3862,  1.3789, -1.4697,  0.2311]])\n"
     ]
    }
   ],
   "source": [
    "# as for the matrix multiplication (not the element wise one)\n",
    "# we should a built-in function where the result depends hugely on the arguments' dimensions\n",
    "# in other words if the result of the multiplication is mathematically a vector, then the object will have only 1 dimension, if it is a scalar then it will be 0-dimensional\n",
    "print(torch.mm(ones2.T, ones1).size()) # this will be 2 * 1 matrix: or a 2-dimensional vector\n",
    "# if the data type is a problem, then we can convert it easily\n",
    "t = torch.randn(size=(3, 4), dtype=torch.float16)\n",
    "t = t.type(torch.float32)\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  2.,  3.],\n",
      "        [-1.,  3.,  4.]])\n",
      "tensor([[[ 1.,  2.],\n",
      "         [ 3., -1.],\n",
      "         [ 3.,  4.]]])\n"
     ]
    }
   ],
   "source": [
    "# dealing with shapes\n",
    "# be mindful of views are they copied by reference\n",
    "t = torch.tensor([[1, 2, 3], [2, 3, 4]], dtype=torch.float32)\n",
    "t_v = t.view(1, 3, 2)\n",
    "\n",
    "# changing a view affects the original tensor\n",
    "t_v[0, 1, 1] = -1\n",
    "# let's see the change reflected on 't' \n",
    "print(t, t_v, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  2.],\n",
      "        [ 3., -1.],\n",
      "        [ 3.,  4.]])\n"
     ]
    }
   ],
   "source": [
    "# fed up with dimensions of value 1: squeeze() is ur best friend\n",
    "squeezed_t = t_v.squeeze()\n",
    "print(squeezed_t)\n",
    "# with squeezing comes unsqueezing: adding another dimension of value 1: the dimension should be specified\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('ds_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7bb0ce5cb6b092cde9f0ba713d915425207ed6ea08d3ede97530b87c251a3aee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
