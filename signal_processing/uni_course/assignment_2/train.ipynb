{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "import keras.backend as K\n",
    "matplotlib.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1440\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "IMAGE_SHAPE = (224, 224)\n",
    "TRAINING_DATA_DIR = os.path.join(os.getcwd(), 'training')\n",
    "VALID_DATA_DIR = os.path.join(os.getcwd(), 'validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2628 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255\n",
    ")\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    TRAINING_DATA_DIR,\n",
    "    shuffle=True,\n",
    "    target_size=IMAGE_SHAPE,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 657 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "valid_generator = datagen.flow_from_directory(\n",
    "    VALID_DATA_DIR,\n",
    "    shuffle=False,\n",
    "    target_size=IMAGE_SHAPE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(num_classes):\n",
    "    model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu', \n",
    "                           input_shape=(224, 224, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=2),\n",
    "    tf.keras.layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=2),\n",
    "    tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "model = build_model(num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_f1(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
    "    \n",
    "    return f1_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_6 (Conv2D)           (None, 222, 222, 16)      448       \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 111, 111, 16)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 109, 109, 16)      2320      \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 54, 54, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 52, 52, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 26, 26, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 21632)             0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 32)                692256    \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 699,730\n",
      "Trainable params: 699,730\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "    metrics=[get_f1]\n",
    ")\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "10/10 [==============================] - 5s 496ms/step - loss: 0.0462 - get_f1: 0.9875 - val_loss: 0.1430 - val_get_f1: 0.9688\n",
      "Epoch 2/8\n",
      "10/10 [==============================] - 5s 447ms/step - loss: 0.1110 - get_f1: 0.9719 - val_loss: 0.1695 - val_get_f1: 0.9375\n",
      "Epoch 3/8\n",
      "10/10 [==============================] - 5s 436ms/step - loss: 0.0677 - get_f1: 0.9844 - val_loss: 0.1113 - val_get_f1: 0.9688\n",
      "Epoch 4/8\n",
      "10/10 [==============================] - 5s 450ms/step - loss: 0.0483 - get_f1: 0.9906 - val_loss: 0.1625 - val_get_f1: 0.9531\n",
      "Epoch 5/8\n",
      "10/10 [==============================] - 5s 445ms/step - loss: 0.1004 - get_f1: 0.9500 - val_loss: 0.1027 - val_get_f1: 0.9688\n",
      "Epoch 6/8\n",
      "10/10 [==============================] - 5s 460ms/step - loss: 0.0767 - get_f1: 0.9812 - val_loss: 0.2513 - val_get_f1: 0.9531\n",
      "Epoch 7/8\n",
      "10/10 [==============================] - 5s 468ms/step - loss: 0.0726 - get_f1: 0.9750 - val_loss: 0.1590 - val_get_f1: 0.9688\n",
      "Epoch 8/8\n",
      "10/10 [==============================] - 5s 461ms/step - loss: 0.0323 - get_f1: 0.9906 - val_loss: 0.0853 - val_get_f1: 0.9688\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 8\n",
    "BATCH_SIZE = 128\n",
    "history = model.fit(train_generator,\n",
    "                    steps_per_epoch=train_generator.samples // BATCH_SIZE // 2,\n",
    "                    epochs=EPOCHS,\n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps= valid_generator.samples // BATCH_SIZE // 2,\n",
    "                    verbose=1\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir('Ayhem_Bouabid'):\n",
    "    model.save(\"Ayhem_Bouabid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "reconstructed_model = keras.models.load_model('Ayhem_Bouabid', compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "10/10 [==============================] - 8s 522ms/step - loss: 0.0887 - get_f1: 0.9781 - val_loss: 0.2231 - val_get_f1: 0.9688\n",
      "Epoch 2/8\n",
      "10/10 [==============================] - 5s 450ms/step - loss: 0.0711 - get_f1: 0.9875 - val_loss: 0.1952 - val_get_f1: 0.9688\n",
      "Epoch 3/8\n",
      "10/10 [==============================] - 5s 467ms/step - loss: 0.0408 - get_f1: 0.9875 - val_loss: 0.1825 - val_get_f1: 0.9688\n",
      "Epoch 4/8\n",
      "10/10 [==============================] - 5s 442ms/step - loss: 0.0372 - get_f1: 0.9875 - val_loss: 0.1396 - val_get_f1: 0.9688\n",
      "Epoch 5/8\n",
      "10/10 [==============================] - 5s 479ms/step - loss: 0.0485 - get_f1: 0.9875 - val_loss: 0.0777 - val_get_f1: 0.9844\n",
      "Epoch 6/8\n",
      "10/10 [==============================] - 5s 462ms/step - loss: 0.0800 - get_f1: 0.9844 - val_loss: 0.4010 - val_get_f1: 0.9062\n",
      "Epoch 7/8\n",
      "10/10 [==============================] - 5s 464ms/step - loss: 0.0818 - get_f1: 0.9781 - val_loss: 0.3913 - val_get_f1: 0.9531\n",
      "Epoch 8/8\n",
      "10/10 [==============================] - 5s 447ms/step - loss: 0.0640 - get_f1: 0.9937 - val_loss: 0.2008 - val_get_f1: 0.9688\n",
      "21/21 [==============================] - 5s 244ms/step - loss: 0.0863 - get_f1: 0.9851\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0863087847828865, 0.9851190447807312]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reconstructed_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "    metrics=[get_f1]\n",
    ")\n",
    "\n",
    "EPOCHS = 8\n",
    "BATCH_SIZE = 128\n",
    "history = reconstructed_model.fit(train_generator,\n",
    "                    steps_per_epoch=train_generator.samples // BATCH_SIZE // 2,\n",
    "                    epochs=EPOCHS,\n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps= valid_generator.samples // BATCH_SIZE // 2,\n",
    "                    verbose=1\n",
    "                    )\n",
    "\n",
    "print(\"#\" * 100)\n",
    "reconstructed_model.evaluate(valid_generator)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('ds_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7bb0ce5cb6b092cde9f0ba713d915425207ed6ea08d3ede97530b87c251a3aee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
