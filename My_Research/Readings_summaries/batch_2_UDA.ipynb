{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paper 8:\n",
    "* [link](https://arxiv.org/pdf/1409.7495.pdf)\n",
    "* main idea:\n",
    "    1. Assuming the usual setting of ***UDA***, the authors introduce an additional label for each source training sample: $d \\in \\{0, 1\\}$: belongs to source or not\n",
    "    2. Assuming the Neural Network can be split into a feature extractor $G_{f}$ and a label predictor, the idea is to introduce an additional domain predictor (a feed forward block) predicting $d$.\n",
    "    3. The parameters of $G_f$, $\\theta_f$ are optimized to both\n",
    "        * minimize the loss of the label predictor (obtain discriminative features)\n",
    "        * maximize the loss of the domain predictor (learn domain invariant features)\n",
    "    4. Additionally, the parameters $\\theta_d$ are optimized to minimize the loss of the domain predictor\n",
    "\n",
    "* Main intuition:\n",
    "    * According to the [domain shift](https://sci-hub.ru/10.1016/s0378-3758(00)00115-4) assumption, minimizing the discrepancy  distributions: $G_f(x, \\theta_f| x ~ S(x))$, $G_f(x, \\theta_f| x ~ T(x))$ will lead to high performance in both domains (distributions)\n",
    "    * Estimating each of these distributions is non trivial because of high dimensionality, and changing values over the training process\n",
    "    * one way to estimate such discrepancy is the difference between the loss of the domain predictor / classifier assuming $\\theta_d$ were optimized to differentiate between them \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paper 9: How transferrable are deep features\n",
    "* [link]()\n",
    "* main ideas / contributions:\n",
    "    1. the higher the layers, the lower the generality is: the number of layers frozen should be tuned as well\n",
    "    2. The transferability of features is affected not only by the features' specificality but also with codependency between neurons: In other words certain layers (mainly in the middle of the network) might learn fragile features that heavily depend on the previous layers. The transferrability is negatively impacted when only a subset of these co-dependent layers is transferred\n",
    "    3. Using weights pretrained on a different but similar (not sure of the importance of similarity in this particular conclusion) task can improve the performance.\n",
    " "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
