{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview1\n",
    "This notebook is created to save notes from the lectures of the GAN specialization offered on Coursera\n",
    " \n",
    "## Week1\n",
    "### Intuition\n",
    "Let's start with the big picture\n",
    "ML can be divided into 2 main branches: discriminative and Generative:\n",
    "\n",
    "1. Discriminative: simply what to know what a set of numbers represents out of a very specific set of possibilities: basically what is that ? (that is $X$ btw) or what makes $y$ (belongs to?) **$Y$**\n",
    "2. Generative: seeks to answer: how can I construct an instance of $Y$ ? (best explanation so far)\n",
    "\n",
    "More formally:\n",
    "\n",
    "1. Discriminative: $P(Y|X)$ given $X$\n",
    "2. Generative: a possible $X$ given $Y$, the possible is expressed by some noise $\\epsilon$\n",
    "\n",
    "well there are 2 types of GMs:\n",
    "\n",
    "1. Auto encoders: Encoder-Decoder architecture: The intuition is as follows: build a component that can determine what makes $x$ X, and a component that can build (with a touch of indeterminism) given a specific instance of the core of $X$: something like an architect: encoder and a construction team: :decoder.\n",
    "2. GANs: Generator and Discriminator. The intuition is as follows: if I have an extremely competent inspector that can distinguishes between fake and real $x$'s, but I can still fool him. Then, my $x$ are too realistic and roughly speaking I know how to construct a possible $x$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "Well, The course do not introduce any interesting details as they focus more on the general flow:\n",
    "\n",
    "1. Discrimininator is a classifier: (not much of a surprise isn't?) Given a set of noise vectors + some real examples, the current generator will turn the noise vectors into fake images. The discriminator is trained on a binary classification task: Real or Fake\n",
    "\n",
    "2. Generator: Not very clear so far. Yet, the workflow is as follows: Given a noise vec, create an image, pass it to the discriminator and update $\\theta_g$ according to the discriminator's output. The generator's output is heavily influenced by the datasets it is trained on: The most frequent features are more likely to appear in the generator's output.\n",
    "\n",
    "3. The training is iterative:\n",
    "    * train the discriminator, given $\\theta_g$, update $\\theta_d$\n",
    "    * train the generator: given $\\theta_d$, update $\\theta_g$: THE LABELS PASSED TO THE DISCRIMINATOR SHOULD BE ALL `REAL`, THE LOSS IS PROPORTIONAL TO HOW WELL THE DISCRIMINATOR DIFFERENTIATES BETWEEN THE FAKE IMAGES AND THE REAL ONES...\n",
    "    * an important NOTE to keep in mind: training a generator with a superior discriminator is not a fruitful process. As an almost certain output from a discriminator cannot help the generator learn\n",
    "    * It is more likely to have a superior Discriminator than a superior generator. The training process should account for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
