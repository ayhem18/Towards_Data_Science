{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "This notebook was created to save and make notes of the fabulous NLP book:  **Handbook Of Natural Language Processing**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifical Approaches\n",
    "## The classical toolkit\n",
    "The classical techniques first tackled a nature language by first decomposing the processing process into different steps / stages:\n",
    "1. tokenization\n",
    "2. lexical analysis\n",
    "3. syntactic analysis\n",
    "4. semantic analysis\n",
    "5. pragmatic analysis\n",
    "\n",
    "From the last layer, we proceed to extract the speaker's intended meaning.  \n",
    "\n",
    "The book dives into each of these $5$ steps"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text preprocessing\n",
    "This is defined as the skill of converting text (boiled down to a sequence of bits) into a totally different sequence of meaningful linguistic units. Among the main techniques there is Word Segmentation: dividing a piece of text into different words, this raises the question of what determines the boundaries of a word, sentence segmentation: dividing a piece of text into different sentences. These two techniques are interdependent.  \n",
    "Text preprocessing should consider different aspect of the language such as the writing system. There are $3$ main system:\n",
    "1. logographic: a word is built out of a large number of symbols (some can reach $1000$ symbols)\n",
    "2. syllabic: a symbol represents a syllable (at least two different sounds combined)\n",
    "3. alphabetic: a symbol represents a sound.  \n",
    "\n",
    "Due to the cultural exchange taking place in the modern age, no language is purely based on a single writing system. nevertheless, it is safe to state that English is mostly alphabetic.   \n",
    "### Language identification: The Language dependence Challenge\n",
    "Well this task does not require a heavy machinery of NLP techniques. The first step is to consider the range of characters in the used language (mainly the mapping of the characters to their numerical values in the encoding system). The first step already narrows down the choice. The second part is a bit trickier as several language could share the same alphabet: Arabic and Persian, Swedish and Danish, european languages in general. This further distinction is mainly based on the distribution of the frequencies of these chracters in the specific set.\n",
    "\n",
    "### Corpus dependence\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Robustness represented a major challenge for the earlier NLP systems. With the explosion of content on the internet, textual data is found in abandance. Nevertheless, the quality did not follow along with the quantity as most piece of text do not follow grammars, punctuations as well as formatting rules that some of the earlier NLP were built upon. It is evident that NLP requires robust algorithms capable of addressing a large number of irregularities associated with 1. difficulty to actually set and formally define rules for producing text 2. the slim likelihood that individuals will actually follow these rules if they ever formalized."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## application dependence\n",
    "There is no universal criteria determining what constitutes a word, as the possible definitions of such entity can be greatly vary with respect to the language, context, writing system or even the system actually processing the text. One main example is the contraction: I am $\\rightarrow$ I'm. Different corpora might treat this linguistic entity differently depending on several factors. Therefore, tokens' representation highly depends on the final processing purpose: speech recognition, classification tasks, text generation... "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization \n",
    "The challenges associated with segmentation can be explained by two main factors:\n",
    "1. writing system: I have already elaborated on that above\n",
    "2. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('ds_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7bb0ce5cb6b092cde9f0ba713d915425207ed6ea08d3ede97530b87c251a3aee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
