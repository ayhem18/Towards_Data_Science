{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lec 3: Object Detection \n",
    "Let's talk object detection now. The first approach was using sliding 2D CNNs. Let's consider a rectangle of predefined dimensions. We slide through the given image, and each resulting snapshot will be passed to a CNN to determine whether there is an object there or not. This model, as its explanation sounds is quite simple. Thus, it comes with a number of issues:\n",
    "1. What if an object in the image is improportionally large / small in comparison to the detection box\n",
    "2. The model is definitely not efficient\n",
    "\n",
    "* The basic model was improved further by first considering a smaller copy of the given image. Performing the same process. If the results are positive (an object is there), then the image is resized to larger dimensions. The initial procedure is only performed in regions where the an object detected in smaller copies. The algorithm's success is quite dependent on the efficiency of the first step.\n",
    "\n",
    "## Selective Search\n",
    "It is an algorithm that detects interesting objects based on a number of heuristics. The boxes of these interesting objects are later passed to a CNN.\n",
    "\n",
    "## Intersection Over Union\n",
    "Assuming we have the ground truth bounding boxes, we consider the boxes predicted by the model. One metric to evaluate the performance is called Intersection Over Union. The main idea is to calculate the ratio of I over U where:\n",
    "* I is the area of the intersection of the two boxes\n",
    "* U is the area covered by the union of the two boxes.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Non-maximum supression\n",
    "* One major issue about selective search empowered algorithms is reporting parts of what we (humans) consider an atomic object as stand alone objects: the leg / head of a cat. Therefore, selective search would return multiple suggestions. Nevertheless IOU would generally evaluate these individual parts with certain high values that cannot be just ignored.\n",
    "*  WELL, you probably guessed it, we need to come up with some filtering process, right ?. The main algorithm is referred to as non maximum supression. Let me describe it in my own words:\n",
    "1. first consider the proposals: sort them according to a certain metric $S$ and put them in a list, say $B$. Take the one with the highest metric\n",
    "2. The current object selected is compared to every object in $B$\n",
    "3. Assuming a IOU treshold is already defined $N_T$, then any object with IOU(current best object, object) $ \\geq N_T$ will be removed from $B$ or using the technical term: suppressed\n",
    "4. Repeat the process until $B$ is empty.  \n",
    "\n",
    "The algorithm is quadratic with respect to the number of initial proposals and linear at best. Besides performance, The NMS algorithm introduces additional issues: The choice of $N_T$ is quite critical, and might suppress legitimate and quite objectively good objects in a crawded image. As a solution for the 2nd issue, the soft-NMS was proposed.  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RCNN\n",
    "RCNN: an abbreviation of Regions with CNN features. It is based on selective search where the latter extracts around 2k regions. These regions are then evaluated by a CNN.\n",
    "This architecture is quite problematic for a number of reasons: \n",
    "1. Evaluting 2000k classifications per single image\n",
    "2. very slow performanace\n",
    "3. selective search is based on heuristics (a static algorithm). Such algorithm might not be effective for all data problems\n",
    "\n",
    "## Fast RCNN\n",
    "The main twick with FRCNN is first applying convolution layers (no FC ones) and then extracting the different regions from the resulting image. The proposals are then passed to the fully connected part of the architecture.\n",
    "\n",
    "The image resulting from the convolution operations is referred to as the feature map. Selective search produces cuts of different shapes. They cannot be fed directly to the Fully connected layers as they require uniform dimensions. The solution is ROI pooling which is an abbreviation of Region Of Interest Pooling. The latter incorporates Max Pooling in a mechanism that guarantees uniform output shape regardless of the input shape.\n",
    "\n",
    "One important note is that selective search cannot be applied directory on a feature map. Well, we can't just sit down and cross our arms. We still apply the algorithm on the original image. Nevertheless, using the ratio between the feature map shape and the original's to map the coordinates of the interesting regions to their correspondings in the feature map. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7bb0ce5cb6b092cde9f0ba713d915425207ed6ea08d3ede97530b87c251a3aee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
