{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical Tips\n",
    "This Notebook is created to track the different difficult practical situations I face during practicing machine learning as well as the solutions for them. Additionally, I will try to save all the links that with the original ideas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Training and test Sets: (dis)similarity:\n",
    "If the regularization techniques do not improve the overfitting problems to a significant extent, one possible scenario is that test and training sets are in fact of different distributions. Thus, you cannot expect the model to have a low generalization error. How to work on that ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main point is to create a model to classify whether a sample belongs to the training or test set. One possible model would be a DecisionTreeClassifier. If the area under the curve is quite high: mainly above 0.8, then there is a strong indication of covariante shift which basically means that the test and training datasets are of different contributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Linear Regression and its extensions\n",
    "The linear Regression model is the most basic regression model out there. For small datasets, this technique might easily overfit and thus result in high generalization error. Among the extensions, we can mention: \n",
    "* Lasso: uses the ***l1*** penatly: absolute value of weights\n",
    "* Ridge: uses the ***l2*** penatly: square of weights\n",
    "* Elastic Net: uses a combination of both  \n",
    "\n",
    "Each of these techniques require using scaling the data:\n",
    "* normalization: minimum value to $0$ and maximum to $1$\n",
    "* standard scaler: setting the mean to $0$ and variance to $1$  \n",
    "1. These models are to be used generally with a small dataset: $m \\leq 10 ^ 5$.  Otherwise, it might be better to use stochastic gradient descent as the main optimizer by employing: ***SGDRegressor***\n",
    "2. Lasso, and Elastic tend to minimize significantly the coefficients. They are useful when certain features are not sure to be relevant\n",
    "3. Ridge is more balanced, as it distributes the shrinkage. It is better to use it when most of the features are known to be relevant\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Standard Scaler\n",
    "The method fit_transform, will first calculate the variance and mean of the passed random variable then apply the transformation:\n",
    "$\\begin{align} X = \\frac{X - \\mu}{\\sigma}\\end{align}$\n",
    "The same transformation should be applied on the test data set and by same, it is meant to save the values of the parameters $\\mu$ and $\\sigma$. Thus, when calling the scaler on test data it should be called with the method transform () and not fit_transform().\n",
    "\n",
    "[source](https://datascience.stackexchange.com/questions/12321/whats-the-difference-between-fit-and-fit-transform-in-scikit-learn-models#:~:text=fit%20computes%20the%20mean%20and%20std%20to%20be,std%29.%20fit_transform%20does%20both%20at%20the%20same%20time.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. DecisionTree: Tips\n",
    "* A tree with a large number of features tends to overfit. Consider features selection techniques\n",
    "* it is insightful to understand the structure of the tree. Use this [link](https://scikit-learn.org/stable/auto_examples/tree/plot_unveil_tree_structure.html#sphx-glr-auto-examples-tree-plot-unveil-tree-structure-py) as a guide\n",
    "* max_depth, min_samples_leaf, min_samples_split"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('ds_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "08488e93894ea7be7272109919d40edb52233f14daf834f5f2387122a81730e1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
