{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer, load_digits\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>29.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211.3375</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>30.00</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>25.00</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass     sex    age  sibsp  parch      fare embarked\n",
       "0         1       1  female  29.00      0      0  211.3375        S\n",
       "1         1       1    male   0.92      1      2  151.5500        S\n",
       "2         0       1  female   2.00      1      2  151.5500        S\n",
       "3         0       1    male  30.00      1      2  151.5500        S\n",
       "4         0       1  female  25.00      1      2  151.5500        S"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('titanic.csv')\n",
    "# removing name column\n",
    "data = data.drop(['name'], axis = 1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# split data\n",
    "x_train, x_test, y_train, y_test = train_test_split(data.loc[:, 'pclass':], data['survived'],\n",
    "                                                    test_size=0.2, stratify=data['survived'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Data preprocessing\n",
    "NB can handle discrete features data which can be useful with categorical data.\n",
    "\n",
    "Let's see one of the advantages of NB classifier. NB is not affected by data scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ayhem18/Ayhem18/DEV/Data_science/Towards_Data_Science/ds_env/lib/python3.10/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/ayhem18/Ayhem18/DEV/Data_science/Towards_Data_Science/ds_env/lib/python3.10/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# imputing missing values\n",
    "imputer = SimpleImputer(strategy='most_frequent')\n",
    "imputer.fit(x_train)\n",
    "x_train = pd.DataFrame(imputer.transform(x_train), columns=x_train.columns)\n",
    "x_test = pd.DataFrame(imputer.transform(x_test), columns=x_test.columns)\n",
    "\n",
    "# one-hot-encode categorical features\n",
    "def ohe_new_features(df, features_name, encoder):\n",
    "    new_feats = encoder.transform(df[features_name])\n",
    "    # create dataframe from encoded features with named columns\n",
    "    new_cols = pd.DataFrame(new_feats, dtype=int, columns=encoder.get_feature_names(features_name))\n",
    "    new_df = pd.concat([df, new_cols], axis=1)\n",
    "    new_df.drop(features_name, axis=1, inplace=True)\n",
    "    return new_df\n",
    "\n",
    "encoder = OneHotEncoder(sparse=False, drop='first')\n",
    "f_names = ['sex', 'embarked']\n",
    "encoder.fit(x_train[f_names])\n",
    "x_train = ohe_new_features(x_train, f_names, encoder)\n",
    "x_test = ohe_new_features(x_test, f_names, encoder)\n",
    "\n",
    "# feature scaling\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(x_train)\n",
    "scaled_x_train = pd.DataFrame(scaler.transform(x_train), columns=x_train.columns)\n",
    "scaled_x_test = pd.DataFrame(scaler.transform(x_test), columns=x_test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Train and test two NB models ono the data before scaling and one after scaling\n",
    "and observe if the accuracy change with scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy before scaling: 0.7862595419847328\n",
      "Accuracy after scaling: 0.7862595419847328\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "\n",
    "# Write code here\n",
    "nb = GaussianNB()\n",
    "nb.fit(x_train, y_train)\n",
    "y_pred = nb.predict(x_test)\n",
    "print('Accuracy before scaling:', accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Write code here\n",
    "nb = GaussianNB()\n",
    "nb.fit(scaled_x_train, y_train)\n",
    "y_pred = nb.predict(scaled_x_test)\n",
    "print('Accuracy after scaling:', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Regularization\n",
    "What is [Elastic-Net](https://scikit-learn.org/stable/modules/linear_model.html#elastic-net)?\n",
    "How can you specify the contribution of each part using l1 ration\n",
    "\n",
    "Apply classification on the breast cancer dataset with no regularization, l1,\n",
    "l2, and elastic-net."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Loading Breast cancer dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X, y = load_breast_cancer(return_X_y=True)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Fitting both Lasso and Ridge\n",
    "\n",
    "Fit 3 models: Lasso and Ridge and Elastic-Net.\n",
    "Then print their accuracy and coefficients and notice the difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso's coefficients: \n",
      "\t-0.0\n",
      "\t-0.0\n",
      "\t-0.0\n",
      "\t-0.00023817212611857441\n",
      "\t-0.0\n",
      "\t-0.0\n",
      "\t-0.0\n",
      "\t-0.0\n",
      "\t-0.0\n",
      "\t-0.0\n",
      "\t-0.0\n",
      "\t-0.0\n",
      "\t-0.0\n",
      "\t0.0\n",
      "\t-0.0\n",
      "\t-0.0\n",
      "\t-0.0\n",
      "\t-0.0\n",
      "\t-0.0\n",
      "\t-0.0\n",
      "\t-0.0\n",
      "\t-0.0\n",
      "\t-5.5678468059991235e-05\n",
      "\t-0.0004842808015410192\n",
      "\t-0.0\n",
      "\t-0.0\n",
      "\t-0.0\n",
      "\t-0.0\n",
      "\t-0.0\n",
      "\t-0.0\n",
      "Lasso's accuracy: 0.8421052631578947\n",
      "\n",
      "Ridge's coefficients: \n",
      "\t[ 0.34894376  0.00306089 -0.01026111 -0.00256649 -0.23636864 -0.03366272\n",
      " -0.2625773  -0.44952068 -0.30465557 -0.01585031 -0.2550041   0.05442145\n",
      " -0.08093722  0.00277543 -0.09661121  0.1150606   0.31887857 -0.07943448\n",
      " -0.04408642  0.01113721 -0.53484972 -0.02928854  0.01885468  0.00250438\n",
      " -0.55373343 -0.22838262 -0.42514715 -0.90252352 -0.62371346 -0.12162393]\n",
      "Ridge's accuracy: 0.9707602339181286\n",
      "\n",
      "ElasticNet's coefficients: \n",
      "\t-0.0\n",
      "\t-0.0\n",
      "\t-0.0\n",
      "\t0.0\n",
      "\t-0.0\n",
      "\t-0.0\n",
      "\t-0.0\n",
      "\t-0.0\n",
      "\t-0.0\n",
      "\t-0.0\n",
      "\t-0.0\n",
      "\t-0.0\n",
      "\t-0.0\n",
      "\t0.0\n",
      "\t-0.0\n",
      "\t-0.0\n",
      "\t-0.0\n",
      "\t-0.0\n",
      "\t-0.0\n",
      "\t-0.0\n",
      "\t-0.0\n",
      "\t-0.0008601143429825037\n",
      "\t-0.010642182151360069\n",
      "\t-1.1048645494854392e-05\n",
      "\t-0.0\n",
      "\t-0.0\n",
      "\t-0.0\n",
      "\t-0.0\n",
      "\t-0.0\n",
      "\t-0.0\n",
      "ElasticNet's accuracy: 0.8830409356725146\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Write code here\n",
    "lasso = Lasso()\n",
    "ridge = RidgeClassifier()\n",
    "elasticnet = ElasticNet()\n",
    "\n",
    "def model(model, model_name, print_zero=False):\n",
    "    global x_train, x_test, y_train, y_test\n",
    "    # the model is assumed to be linear in the function\n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "    \n",
    "    if len(np.unique(y_pred)) > 2:\n",
    "        y_pred = y_pred > 0.5\n",
    "    score = accuracy_score(y_test, y_pred)   \n",
    "    \n",
    "    coefs = model.coef_ \n",
    "    print(f\"{model_name}'s coefficients: \")\n",
    "    for c in coefs:\n",
    "        if c.all() != 0 :\n",
    "            print(f\"\\t{c}\")\n",
    "        elif c.all() == 0 and print_zero:\n",
    "            print(f\"\\t{c}\")\n",
    "            \n",
    "    print(f\"{model_name}'s accuracy: {score}\")\n",
    "    print()\n",
    "    \n",
    "models = [lasso, ridge, elasticnet]\n",
    "names = [\"Lasso\", \"Ridge\", \"ElasticNet\"]\n",
    "\n",
    "for m, n in zip(models, names):\n",
    "    model(m, n, print_zero=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that that the classifiers can be order by their accuracy:\n",
    "1. Ridge\n",
    "2. Elastic Net\n",
    "3. Lasso\n",
    "This can be understood through the coefficient associated with each of these models.\n",
    "* 'L1' regularization sets the features seen as non-relevant (or of little relevance) to zero. However, Even though some features individually are not as relevant, when combined can improve performance as they tackle mainly the differences between similar classes\n",
    "* 'L2' generally does not set features to zero, but to extremely small values. This is reflected with the highest accuray as it is not evident that most of features are completely irrelevant or redundant.\n",
    "* Elastic net is in between having both forms of regularization: the feature deemed as irrelevant are set to $0$. However those who are not are assigned larger coefficients. This combinations is further reflected in an accuracy between both Ridge and Lasso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# KNN\n",
    "Compare KNN vs logistic regression\n",
    "\n",
    "---\n",
    "In ML images can be flattened to 1D vector of pixels, then we can train our\n",
    "models on them considering each pixel as a feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape (1797, 8, 8)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now we have 1797 images flattened to 64-values vectors\n"
     ]
    }
   ],
   "source": [
    "# Based on https://github.com/hsu-ai-course/hsu.ai/blob/master/code/12.%20kNN%20and%20ANN%20for%20MNIST.ipynb\n",
    "digits = load_digits()\n",
    "\n",
    "print(\"Dataset shape\", digits.images.shape)\n",
    "\n",
    "# show first image\n",
    "plt.title(f\"Target: {digits.target[0]}\")\n",
    "plt.imshow(digits.images[0], cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "# To apply an classifier on this data, we need to flatten the image, to\n",
    "# turn the data in a (samples, feature) matrix:\n",
    "n_samples = len(digits.images)\n",
    "X = digits.images.reshape((n_samples, -1))\n",
    "y = digits.target\n",
    "print(\"Now we have {} images flattened to {}-values vectors\".format(*X.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Train a KNN and LR models and compare their results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "CV = StratifiedKFold(n_splits=4, shuffle=True, random_state=11)\n",
    "\n",
    "# Write code here\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# let's find the best the hyperparameters for knn\n",
    "knn_params = {\"n_neighbors\": range(10, 20), \"weights\": ['uniform', 'distance']}\n",
    "knn_searcher = GridSearchCV(knn, knn_params, scoring='accuracy', cv=CV)\n",
    "knn_searcher.fit(X_train, y_train)\n",
    "knn = knn_searcher.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/ayhem18/Ayhem18/DEV/Data_science/Towards_Data_Science/Machine_Learning/Uni_ML_course_notes/week4/self-practice_4.ipynb Cell 20\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ayhem18/Ayhem18/DEV/Data_science/Towards_Data_Science/Machine_Learning/Uni_ML_course_notes/week4/self-practice_4.ipynb#X25sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m LR_params \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mC\u001b[39m\u001b[39m\"\u001b[39m: [\u001b[39m10\u001b[39m \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m i \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m, \u001b[39m4\u001b[39m)]}\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ayhem18/Ayhem18/DEV/Data_science/Towards_Data_Science/Machine_Learning/Uni_ML_course_notes/week4/self-practice_4.ipynb#X25sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m LR_searcher \u001b[39m=\u001b[39m GridSearchCV(LR, LR_params, scoring\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m, cv\u001b[39m=\u001b[39mCV)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/ayhem18/Ayhem18/DEV/Data_science/Towards_Data_Science/Machine_Learning/Uni_ML_course_notes/week4/self-practice_4.ipynb#X25sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m LR_searcher\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ayhem18/Ayhem18/DEV/Data_science/Towards_Data_Science/Machine_Learning/Uni_ML_course_notes/week4/self-practice_4.ipynb#X25sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m LR \u001b[39m=\u001b[39m LR_searcher\u001b[39m.\u001b[39mbest_estimator_\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ayhem18/Ayhem18/DEV/Data_science/Towards_Data_Science/Machine_Learning/Uni_ML_course_notes/week4/self-practice_4.ipynb#X25sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m y_true, y_pred \u001b[39m=\u001b[39m y_test, knn\u001b[39m.\u001b[39mpredict(X_test)\n",
      "File \u001b[0;32m~/Ayhem18/DEV/Data_science/Towards_Data_Science/ds_env/lib/python3.10/site-packages/sklearn/model_selection/_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    869\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[1;32m    870\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    871\u001b[0m     )\n\u001b[1;32m    873\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[0;32m--> 875\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[1;32m    877\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    878\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    879\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Ayhem18/DEV/Data_science/Towards_Data_Science/ds_env/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1379\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1377\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1378\u001b[0m     \u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1379\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[0;32m~/Ayhem18/DEV/Data_science/Towards_Data_Science/ds_env/lib/python3.10/site-packages/sklearn/model_selection/_search.py:822\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    814\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    815\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[1;32m    816\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    817\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    818\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[1;32m    819\u001b[0m         )\n\u001b[1;32m    820\u001b[0m     )\n\u001b[0;32m--> 822\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    823\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    824\u001b[0m         clone(base_estimator),\n\u001b[1;32m    825\u001b[0m         X,\n\u001b[1;32m    826\u001b[0m         y,\n\u001b[1;32m    827\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[1;32m    828\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[1;32m    829\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[1;32m    830\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[1;32m    831\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[1;32m    832\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[1;32m    833\u001b[0m     )\n\u001b[1;32m    834\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[1;32m    835\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[1;32m    836\u001b[0m     )\n\u001b[1;32m    837\u001b[0m )\n\u001b[1;32m    839\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    840\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    841\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    842\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    843\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    844\u001b[0m     )\n",
      "File \u001b[0;32m~/Ayhem18/DEV/Data_science/Towards_Data_Science/ds_env/lib/python3.10/site-packages/joblib/parallel.py:1046\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1044\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1046\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[1;32m   1047\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1050\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1051\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1052\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m~/Ayhem18/DEV/Data_science/Towards_Data_Science/ds_env/lib/python3.10/site-packages/joblib/parallel.py:861\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    859\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    860\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 861\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[1;32m    862\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/Ayhem18/DEV/Data_science/Towards_Data_Science/ds_env/lib/python3.10/site-packages/joblib/parallel.py:779\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    778\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[0;32m--> 779\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[1;32m    780\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    781\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    782\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    783\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    784\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/Ayhem18/DEV/Data_science/Towards_Data_Science/ds_env/lib/python3.10/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m     \u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[1;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/Ayhem18/DEV/Data_science/Towards_Data_Science/ds_env/lib/python3.10/site-packages/joblib/_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[1;32m    570\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    571\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 572\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[0;32m~/Ayhem18/DEV/Data_science/Towards_Data_Science/ds_env/lib/python3.10/site-packages/joblib/parallel.py:262\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    259\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 262\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    263\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/Ayhem18/DEV/Data_science/Towards_Data_Science/ds_env/lib/python3.10/site-packages/joblib/parallel.py:262\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    259\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 262\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    263\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/Ayhem18/DEV/Data_science/Towards_Data_Science/ds_env/lib/python3.10/site-packages/sklearn/utils/fixes.py:117\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    116\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig):\n\u001b[0;32m--> 117\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Ayhem18/DEV/Data_science/Towards_Data_Science/ds_env/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    684\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[1;32m    685\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 686\u001b[0m         estimator\u001b[39m.\u001b[39;49mfit(X_train, y_train, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[1;32m    688\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m    689\u001b[0m     \u001b[39m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    690\u001b[0m     fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/Ayhem18/DEV/Data_science/Towards_Data_Science/ds_env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1158\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1152\u001b[0m     \u001b[39mif\u001b[39;00m effective_n_jobs(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_jobs) \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1153\u001b[0m         warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m   1154\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mn_jobs\u001b[39m\u001b[39m'\u001b[39m\u001b[39m > 1 does not have any effect when\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1155\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39msolver\u001b[39m\u001b[39m'\u001b[39m\u001b[39m is set to \u001b[39m\u001b[39m'\u001b[39m\u001b[39mliblinear\u001b[39m\u001b[39m'\u001b[39m\u001b[39m. Got \u001b[39m\u001b[39m'\u001b[39m\u001b[39mn_jobs\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1156\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m = \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(effective_n_jobs(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_jobs))\n\u001b[1;32m   1157\u001b[0m         )\n\u001b[0;32m-> 1158\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcoef_, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintercept_, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_iter_ \u001b[39m=\u001b[39m _fit_liblinear(\n\u001b[1;32m   1159\u001b[0m         X,\n\u001b[1;32m   1160\u001b[0m         y,\n\u001b[1;32m   1161\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mC,\n\u001b[1;32m   1162\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit_intercept,\n\u001b[1;32m   1163\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mintercept_scaling,\n\u001b[1;32m   1164\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclass_weight,\n\u001b[1;32m   1165\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpenalty,\n\u001b[1;32m   1166\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdual,\n\u001b[1;32m   1167\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[1;32m   1168\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_iter,\n\u001b[1;32m   1169\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtol,\n\u001b[1;32m   1170\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrandom_state,\n\u001b[1;32m   1171\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m   1172\u001b[0m     )\n\u001b[1;32m   1173\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n\u001b[1;32m   1175\u001b[0m \u001b[39mif\u001b[39;00m solver \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39msag\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39msaga\u001b[39m\u001b[39m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/Ayhem18/DEV/Data_science/Towards_Data_Science/ds_env/lib/python3.10/site-packages/sklearn/svm/_base.py:1205\u001b[0m, in \u001b[0;36m_fit_liblinear\u001b[0;34m(X, y, C, fit_intercept, intercept_scaling, class_weight, penalty, dual, verbose, max_iter, tol, random_state, multi_class, loss, epsilon, sample_weight)\u001b[0m\n\u001b[1;32m   1202\u001b[0m sample_weight \u001b[39m=\u001b[39m _check_sample_weight(sample_weight, X, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat64)\n\u001b[1;32m   1204\u001b[0m solver_type \u001b[39m=\u001b[39m _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n\u001b[0;32m-> 1205\u001b[0m raw_coef_, n_iter_ \u001b[39m=\u001b[39m liblinear\u001b[39m.\u001b[39;49mtrain_wrap(\n\u001b[1;32m   1206\u001b[0m     X,\n\u001b[1;32m   1207\u001b[0m     y_ind,\n\u001b[1;32m   1208\u001b[0m     sp\u001b[39m.\u001b[39;49misspmatrix(X),\n\u001b[1;32m   1209\u001b[0m     solver_type,\n\u001b[1;32m   1210\u001b[0m     tol,\n\u001b[1;32m   1211\u001b[0m     bias,\n\u001b[1;32m   1212\u001b[0m     C,\n\u001b[1;32m   1213\u001b[0m     class_weight_,\n\u001b[1;32m   1214\u001b[0m     max_iter,\n\u001b[1;32m   1215\u001b[0m     rnd\u001b[39m.\u001b[39;49mrandint(np\u001b[39m.\u001b[39;49miinfo(\u001b[39m\"\u001b[39;49m\u001b[39mi\u001b[39;49m\u001b[39m\"\u001b[39;49m)\u001b[39m.\u001b[39;49mmax),\n\u001b[1;32m   1216\u001b[0m     epsilon,\n\u001b[1;32m   1217\u001b[0m     sample_weight,\n\u001b[1;32m   1218\u001b[0m )\n\u001b[1;32m   1219\u001b[0m \u001b[39m# Regarding rnd.randint(..) in the above signature:\u001b[39;00m\n\u001b[1;32m   1220\u001b[0m \u001b[39m# seed for srand in range [0..INT_MAX); due to limitations in Numpy\u001b[39;00m\n\u001b[1;32m   1221\u001b[0m \u001b[39m# on 32-bit platforms, we can't get to the UINT_MAX limit that\u001b[39;00m\n\u001b[1;32m   1222\u001b[0m \u001b[39m# srand supports\u001b[39;00m\n\u001b[1;32m   1223\u001b[0m n_iter_max \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(n_iter_)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# let's find the best hyperparameters for LR\n",
    "LR = LogisticRegression(max_iter=5000, solver='liblinear')\n",
    "LR_params = {\"C\": [10 ** i for i in range(-2, 4)]}\n",
    "LR_searcher = GridSearchCV(LR, LR_params, scoring='accuracy', cv=CV)\n",
    "LR_searcher.fit(X_train, y_train)\n",
    "LR = LR_searcher.best_estimator_\n",
    "\n",
    "y_true, y_pred = y_test, knn.predict(X_test)\n",
    "print('KNN', classification_report(y_true, y_pred))\n",
    "\n",
    "y_true, y_pred = y_test, LR.predict(X_test)\n",
    "print('LR', classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Which model performed better? What is the advantages of each model over the other?\n",
    "\n",
    "What is the output of `classification_report` function? How to interpret it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN performed better than Linear Regression with a slight margin. This is refleccted in all different performance metrics. KNN has the ability to  capture non-linear relations that Logistic Regression cannot. The problem is fairly linear since LR manages to predict all classes with high accuracy.\n",
    "\n",
    "The output of the classification report can be interpreted as follows: For each class :\n",
    "* recall represents the number of example correctly classified as the $i$-th class out of the all examples classified as the $i$-th class.\n",
    "* precision represents the number of example correctly classified as the $i$-th class out of the all examples that belong to the $i$-th class: precision serves as the accuracy of that class.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "references:\n",
    "* https://towardsdatascience.com/a-look-at-precision-recall-and-f1-score-36b5fd0dd3ec\n",
    "* https://muthu.co/understanding-the-classification-report-in-sklearn/#:~:text=Understanding%20the%20Classification%20report%20through%20sklearn%20A%20Classification,predictions%20are%20True%20and%20how%20many%20are%20False."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds_env",
   "language": "python",
   "name": "ds_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
