{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Divide the scan into different brain sections "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# let's see how it goes\n",
    "npy_file_path = os.path.join(current_dir, 'ihb.npy')\n",
    "\n",
    "all_data = np.load(npy_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(320, 10, 246)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      160\n",
       "460    160\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "num_nans = [np.isnan(all_data[i]).sum() for i in range(all_data.shape[0])]\n",
    "nan_values = pd.Series(num_nans)\n",
    "nan_values.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1 = [all_data[i] for i in range(all_data.shape[0]) if np.isnan(all_data[i]).sum() == 0]\n",
    "g2 = [all_data[i] for i in range(all_data.shape[0]) if np.isnan(all_data[i]).sum() == 460]\n",
    "\n",
    "g2_nan_distribution = np.zeros(shape=(len(g2), len(g2)))\n",
    "\n",
    "for i1, element1 in enumerate(g2):\n",
    "\tfor i2, element2 in enumerate(g2):\n",
    "\t\tg2_nan_distribution[i1][i2] = all(np.sum(np.isnan(element1), axis=1) == np.sum(np.isnan(element2), axis=1))\n",
    "\n",
    "g2 = [scan[:, :-46] for scan in g2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The first step: group scans of the same scan but with different smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we know for a fact that we have 160 samples belonging to 20 subjects each having\n",
    "\n",
    "# let's calculate the auto correlation of each time sequence in each of scan\n",
    "from typing import Union, List\n",
    "from scipy.signal import correlate2d, correlate\n",
    "\n",
    "def autocorrelation_stats(scan: np.ndarray, aggregate:bool=True) -> Union[List, float]:\t\n",
    "\tassert len(scan) == 10\n",
    "\tauto_correlations =  [float(correlate(scan[i:], scan[:-i])) for i in range(1, 6)]\n",
    "\tif aggregate:\n",
    "\t\treturn np.mean(auto_correlations)\n",
    "\treturn auto_correlations\n",
    "\n",
    "def build_ac_pairs(scans: List[np.ndarray]) -> set:\n",
    "\tauto_corrs = np.zeros(shape=(len(scans), len(scans)))\n",
    "\n",
    "\tfor i1, element1 in enumerate(scans):\n",
    "\t\tfor i2, element2 in enumerate(scans):\n",
    "\t\t\tauto_corrs[i1][i2] = correlate2d(element1, element2, \"valid\").item()\t\n",
    "\t\n",
    "\t# for each row, row[0] represents the closest index to scan[i] in terms of auto correlation\n",
    "\t# row[1] represents the same index\n",
    "\tpaired_scans_by_ac = np.argsort(auto_corrs, axis=-1)[:, -2:]\n",
    "\n",
    "\tpairs = set()\n",
    "\n",
    "\tfor i in range(len(scans)):\n",
    "\t\tassert paired_scans_by_ac[i, 1] == i, \"check the code\"\n",
    "\t\tclosest_scan_index = paired_scans_by_ac[i, 0]\n",
    "\t\tif paired_scans_by_ac[closest_scan_index, 0] == i and (closest_scan_index, i) not in pairs:\n",
    "\t\t\tpairs.add((i, closest_scan_index)) \n",
    "\n",
    "\treturn pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1_pairs, g2_pairs = build_ac_pairs(g1), build_ac_pairs(g2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 80)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(g1_pairs), len(g2_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next step: grouping the different segments of the same scan sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unified_segment_rep(scans: List[np.ndarray], pairs_indices: set) -> List[np.ndarray]:\n",
    "\tavg_segments = []\n",
    "\tfor i1, i2 in pairs_indices:\n",
    "\t\ts1, s2  = scans[i1], scans[i2]\n",
    "\t\tif s1.shape != s2.shape:\n",
    "\t\t\traise ValueError(\"Make sure the code is correct. found pairs with different shapes\")\n",
    "\t\tavg_segments.append((s1 + s2) / 2)\n",
    "\treturn avg_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_g1, avg_g2 = unified_segment_rep(g1, g1_pairs), unified_segment_rep(g2, g2_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's assume that the different scan segments correspond to consecutive time stamps (a far-stretched assumption, but why not ?)\n",
    "# the whole idea here is that if we have two consecutive  segments s1 and s2 from an original sequence \"S\". Then we can see if the auto correlation between [s1, s2] and s1, s2 and [s2, s1], s1 and s2 \n",
    "# for each sequence to \"s1\" to find the best sequence \"s2\", we need \"n\" operations with a total of n^2: pretty much nothing when (n = 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_next_segment(seg_index: int, segments: List[np.ndarray]):\n",
    "\tmax_ac_corr = -float('inf')\n",
    "\tbest_index = None\n",
    "\tbest_order = None\n",
    "\n",
    "\tfor i in range(len(segments)):\n",
    "\t\tif i == seg_index: \n",
    "\t\t\tcontinue\n",
    "\n",
    "\t\t# compound segment\n",
    "\t\tother_seg = segments[i]\n",
    "\t\t# build the bigger sequence\n",
    "\t\tcompound_seg1 = np.concatenate([segments[seg_index], other_seg], axis=0)\n",
    "\t\tcompound_seg2 = np.concatenate([other_seg, segments[seg_index]], axis=0)\n",
    "\n",
    "\t\tc1 = correlate2d(compound_seg1, compound_seg1, \"valid\")\n",
    "\t\tc2 = correlate2d(compound_seg2, compound_seg2, \"valid\")\n",
    "\t\tcorr = max(c1, c2)\n",
    "\n",
    "\t\tif corr > max_ac_corr:\n",
    "\t\t\tcorr = max_ac_corr \n",
    "\t\t\tbest_index = i\n",
    "\t\t\tbest_order = [seg_index, i] if c1 > c2 else [i, seg_index]\n",
    "\n",
    "\treturn best_index, best_order "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s1, s2, s3 = np.concatenate([avg_g1[0], avg_g1[1]], axis=0),np.concatenate([avg_g1[1], avg_g1[2]], axis=0),np.concatenate([avg_g1[0], avg_g1[2]], axis=0)\n",
    "# correlate2d(s1, s1, \"valid\").item(),correlate2d(s2, s2, \"valid\").item(),correlate2d(s3, s3, \"valid\").item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try to find the pairs somehow\n",
    "pairs_avg_g1 = set()\n",
    "for i in range(len(avg_g1)):\n",
    "\tj, _= find_best_next_segment(i, segments=avg_g1)\t\n",
    "\tpairs_avg_g1.add((i, j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0, 79),\n",
       " (1, 79),\n",
       " (2, 79),\n",
       " (3, 79),\n",
       " (4, 79),\n",
       " (5, 79),\n",
       " (6, 79),\n",
       " (7, 79),\n",
       " (8, 79),\n",
       " (9, 79),\n",
       " (10, 79),\n",
       " (11, 79),\n",
       " (12, 79),\n",
       " (13, 79),\n",
       " (14, 79),\n",
       " (15, 79),\n",
       " (16, 79),\n",
       " (17, 79),\n",
       " (18, 79),\n",
       " (19, 79),\n",
       " (20, 79),\n",
       " (21, 79),\n",
       " (22, 79),\n",
       " (23, 79),\n",
       " (24, 79),\n",
       " (25, 79),\n",
       " (26, 79),\n",
       " (27, 79),\n",
       " (28, 79),\n",
       " (29, 79),\n",
       " (30, 79),\n",
       " (31, 79),\n",
       " (32, 79),\n",
       " (33, 79),\n",
       " (34, 79),\n",
       " (35, 79),\n",
       " (36, 79),\n",
       " (37, 79),\n",
       " (38, 79),\n",
       " (39, 79),\n",
       " (40, 79),\n",
       " (41, 79),\n",
       " (42, 79),\n",
       " (43, 79),\n",
       " (44, 79),\n",
       " (45, 79),\n",
       " (46, 79),\n",
       " (47, 79),\n",
       " (48, 79),\n",
       " (49, 79),\n",
       " (50, 79),\n",
       " (51, 79),\n",
       " (52, 79),\n",
       " (53, 79),\n",
       " (54, 79),\n",
       " (55, 79),\n",
       " (56, 79),\n",
       " (57, 79),\n",
       " (58, 79),\n",
       " (59, 79),\n",
       " (60, 79),\n",
       " (61, 79),\n",
       " (62, 79),\n",
       " (63, 79),\n",
       " (64, 79),\n",
       " (65, 79),\n",
       " (66, 79),\n",
       " (67, 79),\n",
       " (68, 79),\n",
       " (69, 79),\n",
       " (70, 79),\n",
       " (71, 79),\n",
       " (72, 79),\n",
       " (73, 79),\n",
       " (74, 79),\n",
       " (75, 79),\n",
       " (76, 79),\n",
       " (77, 79),\n",
       " (78, 79),\n",
       " (79, 78)}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs_avg_g1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i in range(len(avg_g1)):\n",
    "\tj, _ = find_best_next_segment(i, segments=avg_g1)\t\n",
    "\tif (i, j) in pairs_avg_g1 and (j, i) in pairs_avg_g1:\n",
    "\t\tcount += 1\n",
    "\n",
    "print(count)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
